"""
API endpoints –¥–ª—è AI –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∑—é–º–µ
–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞, –ø–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, —ç–∫—Å–ø–æ—Ä—Ç
"""
from fastapi import APIRouter, Depends, HTTPException, status, BackgroundTasks
from fastapi.responses import FileResponse
from sqlalchemy.orm import Session
from typing import List, Dict, Any, Optional

from app.database import get_db
from app.api.auth import get_current_user
from app.schemas.base import APIResponse
from app.schemas.analysis import (
    AnalysisRequest, AnalysisResult as AnalysisResultSchema, BatchAnalysisResponse,
    AnalysisFilter, AnalysisStats, ExportRequest
)
from app.models.vacancy import Vacancy
from app.models.application import Application, AnalysisResult
from app.services.ai_analyzer import AIAnalyzer
from app.utils.exceptions import AIAnalysisError, ValidationError
from app.utils.response import success, created, bad_request, unauthorized, not_found, internal_error
from app.utils.logger import get_logger

logger = get_logger(__name__)

router = APIRouter()


@router.post("/start", response_model=APIResponse)
async def start_analysis(
    analysis_request: AnalysisRequest,
    background_tasks: BackgroundTasks,
    current_user = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    –ó–∞–ø—É—Å–∫ AI –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∑—é–º–µ
    –ú–∞–∫—Å–∏–º—É–º 5 —Ä–µ–∑—é–º–µ –∑–∞ —Ä–∞–∑ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å—Ç–æ–∏–º–æ—Å—Ç–∏
    """
    try:
        from app.models.application import Application
        from app.workers.analysis_jobs import run_ai_analysis_batch
        import uuid

        applications_count = len(analysis_request.application_ids)

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –æ—Ç–∫–ª–∏–∫–æ–≤ –∏ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        applications = db.query(Application).join(Application.vacancy).filter(
            Application.id.in_(analysis_request.application_ids),
            Application.vacancy.has(user_id=current_user.id)
        ).all()

        if len(applications) != applications_count:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail={
                    "error": "APPLICATIONS_NOT_FOUND",
                    "message": "–ù–µ–∫–æ—Ç–æ—Ä—ã–µ –æ—Ç–∫–ª–∏–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
                }
            )

        job_id = str(uuid.uuid4())

        # –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ –≤ —Ñ–æ–Ω–æ–≤–æ–π –∑–∞–¥–∞—á–µ (–±–µ–∑ –ø–µ—Ä–µ–¥–∞—á–∏ db - —Å–æ–∑–¥–∞—ë—Ç—Å—è –≤–Ω—É—Ç—Ä–∏)
        background_tasks.add_task(
            run_ai_analysis_batch,
            analysis_request.application_ids,
            current_user.id,
            analysis_request.force_reanalysis
        )

        analysis_data = {
            "job_id": job_id,
            "message": "–ê–Ω–∞–ª–∏–∑ –ø–æ—Å—Ç–∞–≤–ª–µ–Ω –≤ –æ—á–µ—Ä–µ–¥—å",
            "applications_queued": applications_count,
            "estimated_time_seconds": applications_count * 15  # 15 —Å–µ–∫ –Ω–∞ —Ä–µ–∑—é–º–µ
        }

        return success(data=analysis_data)
    except ValidationError as e:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail={
                "error": "VALIDATION_ERROR",
                "message": str(e)
            }
        )
    except Exception as e:
        import logging
        logger = logging.getLogger(__name__)
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –∞–Ω–∞–ª–∏–∑–∞: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail={
                "error": "ANALYSIS_START_ERROR",
                "message": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}"
            }
        )


@router.post("/start-new", response_model=APIResponse)
async def start_analysis_new_applications(
    vacancy_id: str,
    collection_filter: Optional[str] = None,
    limit: Optional[int] = None,
    background_tasks: BackgroundTasks = BackgroundTasks(),
    current_user = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ –¢–û–õ–¨–ö–û –Ω–æ–≤—ã—Ö (–Ω–µ–ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö) –æ—Ç–∫–ª–∏–∫–æ–≤

    –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ—Ç–∫–ª–∏–∫–∏ 'response' (–Ω–æ–≤—ã–µ) –∏ 'consider' (—Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ–º—ã–µ),
    –Ω–æ –ù–ï –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç 'discard' (–æ—Ç–∫–ª–æ–Ω–µ–Ω–Ω—ã–µ)
    """
    import logging
    logger = logging.getLogger(__name__)
    logger.info(f"[START-NEW] –ó–∞–ø—Ä–æ—Å –Ω–∞ –∞–Ω–∞–ª–∏–∑ –Ω–æ–≤—ã—Ö –æ—Ç–∫–ª–∏–∫–æ–≤: vacancy_id={vacancy_id}, user={current_user.id}")

    try:
        from app.models.application import Application, AnalysisResult
        from app.models.vacancy import Vacancy
        from app.models.subscription import Subscription, SubscriptionStatus
        from app.workers.analysis_jobs import run_ai_analysis_batch
        import uuid

        # –ü–†–û–í–ï–†–ö–ê –õ–ò–ú–ò–¢–û–í –ü–û–î–ü–ò–°–ö–ò
        active_subscription = db.query(Subscription).filter(
            Subscription.user_id == current_user.id,
            Subscription.status.in_([SubscriptionStatus.active, SubscriptionStatus.trial])
        ).first()

        if not active_subscription:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail={
                    "error": "NO_SUBSCRIPTION",
                    "message": "–£ –≤–∞—Å –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–π –ø–æ–¥–ø–∏—Å–∫–∏. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ —Ç–∞—Ä–∏—Ñ."
                }
            )

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑–∞ (–ª–∏–º–∏—Ç—ã)
        can_analyze, error_message = active_subscription.can_analyze()
        if not can_analyze:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail={
                    "error": "LIMIT_EXCEEDED",
                    "message": error_message,
                    "subscription": {
                        "plan_type": active_subscription.plan.plan_type.value if active_subscription.plan else "unknown",
                        "analyses_used": active_subscription.analyses_used_this_month,
                        "analyses_limit": active_subscription.plan.max_analyses_per_month if active_subscription.plan else 0
                    }
                }
            )

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –≤–∞–∫–∞–Ω—Å–∏–∏ –∏ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        vacancy = db.query(Vacancy).filter(
            Vacancy.id == vacancy_id,
            Vacancy.user_id == current_user.id
        ).first()

        if not vacancy:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail={
                    "error": "VACANCY_NOT_FOUND",
                    "message": "–í–∞–∫–∞–Ω—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
                }
            )

        # –ù–∞–π—Ç–∏ –≤—Å–µ –Ω–µ–ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–∫–ª–∏–∫–∏
        query = db.query(Application).outerjoin(
            AnalysisResult,
            Application.id == AnalysisResult.application_id
        ).filter(
            Application.vacancy_id == vacancy_id,
            AnalysisResult.id == None  # –ù–µ—Ç –∞–Ω–∞–ª–∏–∑–∞
        )

        # –§–∏–ª—å—Ç—Ä –ø–æ collection_id
        if collection_filter:
            # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä - –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
            query = query.filter(Application.collection_id.like(f"%{collection_filter}%"))
        else:
            # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º response –∏ consider, –ù–û –ù–ï discard
            from sqlalchemy import or_, and_, not_
            query = query.filter(
                and_(
                    or_(
                        Application.collection_id.like("%response%"),
                        Application.collection_id.like("%consider%")
                    ),
                    not_(Application.collection_id.like("%discard%"))
                )
            )

        # –ü—Ä–∏–º–µ–Ω—è–µ–º limit –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
        if limit and limit > 0:
            query = query.limit(limit)

        unanalyzed_applications = query.all()
        application_ids = [str(app.id) for app in unanalyzed_applications]

        logger.info(f"[START-NEW] –ù–∞–π–¥–µ–Ω–æ {len(application_ids)} –Ω–µ–ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ—Ç–∫–ª–∏–∫–æ–≤ (limit={limit if limit else '–Ω–µ —É–∫–∞–∑–∞–Ω'})")

        if not application_ids:
            logger.info("[START-NEW] –ù–µ—Ç –æ—Ç–∫–ª–∏–∫–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            return success(data={
                "message": "–ù–µ—Ç –Ω–æ–≤—ã—Ö –æ—Ç–∫–ª–∏–∫–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞",
                "applications_queued": 0
            })

        job_id = str(uuid.uuid4())
        user_id_str = str(current_user.id)

        logger.info(f"[START-NEW] –ó–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤–æ–π –∑–∞–¥–∞—á–∏: job_id={job_id}, apps={len(application_ids)}, user={user_id_str}")

        # –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ –≤ —Ñ–æ–Ω–æ–≤–æ–π –∑–∞–¥–∞—á–µ
        background_tasks.add_task(
            run_ai_analysis_batch,
            application_ids,
            user_id_str,  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º UUID –≤ —Å—Ç—Ä–æ–∫—É
            False  # –ù–ï –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        )

        logger.info(f"[START-NEW] –§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ –æ—á–µ—Ä–µ–¥—å")

        analysis_data = {
            "job_id": job_id,
            "message": f"–ê–Ω–∞–ª–∏–∑ {len(application_ids)} –Ω–æ–≤—ã—Ö –æ—Ç–∫–ª–∏–∫–æ–≤ –ø–æ—Å—Ç–∞–≤–ª–µ–Ω –≤ –æ—á–µ—Ä–µ–¥—å",
            "applications_queued": len(application_ids),
            "collection_filter": collection_filter,
            "estimated_time_seconds": len(application_ids) * 15
        }

        return success(data=analysis_data)

    except Exception as e:
        import logging
        logger = logging.getLogger(__name__)
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ–≤—ã—Ö –æ—Ç–∫–ª–∏–∫–æ–≤: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail={
                "error": "ANALYSIS_START_ERROR",
                "message": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}"
            }
        )


@router.post("/reanalyze-all", response_model=APIResponse)
async def reanalyze_all_applications(
    vacancy_id: str,
    background_tasks: BackgroundTasks = BackgroundTasks(),
    current_user = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    –ü–µ—Ä–µ–∞–Ω–∞–ª–∏–∑ –í–°–ï–• –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ—Ç–∫–ª–∏–∫–æ–≤ —Å –Ω–æ–≤—ã–º –ø—Ä–æ–º–ø—Ç–æ–º

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç force_reanalysis=True –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∞–Ω–∞–ª–∏–∑–æ–≤
    –ü–æ–ª–µ–∑–Ω–æ –ø–æ—Å–ª–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–æ–º–ø—Ç–∞ AI –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –µ–¥–∏–Ω–æ–π –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏ –æ—Ü–µ–Ω–∫–∏
    """
    try:
        from app.models.application import Application, AnalysisResult
        from app.models.vacancy import Vacancy
        from app.workers.analysis_jobs import run_ai_analysis_batch
        import uuid

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–∏
        vacancy = db.query(Vacancy).filter(
            Vacancy.id == vacancy_id,
            Vacancy.user_id == current_user.id
        ).first()

        if not vacancy:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail={
                    "error": "VACANCY_NOT_FOUND",
                    "message": "–í–∞–∫–∞–Ω—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
                }
            )

        # –ü–æ–ª—É—á–∞–µ–º –í–°–ï –æ—Ç–∫–ª–∏–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã
        analyzed_applications = db.query(Application).join(
            AnalysisResult,
            Application.id == AnalysisResult.application_id
        ).filter(
            Application.vacancy_id == vacancy_id
        ).all()

        if not analyzed_applications:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail={
                    "error": "NO_ANALYZED_APPLICATIONS",
                    "message": "–ù–µ—Ç –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ—Ç–∫–ª–∏–∫–æ–≤ –¥–ª—è –ø–µ—Ä–µ–∞–Ω–∞–ª–∏–∑–∞"
                }
            )

        application_ids = [str(app.id) for app in analyzed_applications]
        job_id = str(uuid.uuid4())

        # –ó–∞–ø—É—Å–∫ –ø–µ—Ä–µ–∞–Ω–∞–ª–∏–∑–∞ –≤ —Ñ–æ–Ω–æ–≤–æ–π –∑–∞–¥–∞—á–µ —Å force_reanalysis=True
        background_tasks.add_task(
            run_ai_analysis_batch,
            application_ids,
            str(current_user.id),  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º UUID –≤ —Å—Ç—Ä–æ–∫—É
            True  # force_reanalysis=True - –∫–ª—é—á–µ–≤–æ–π –ø–∞—Ä–∞–º–µ—Ç—Ä!
        )

        analysis_data = {
            "job_id": job_id,
            "message": f"–ü–µ—Ä–µ–∞–Ω–∞–ª–∏–∑ {len(application_ids)} —Ä–µ–∑—é–º–µ —Å –Ω–æ–≤—ã–º –ø—Ä–æ–º–ø—Ç–æ–º –∑–∞–ø—É—â–µ–Ω",
            "applications_queued": len(application_ids),
            "estimated_time_seconds": len(application_ids) * 15,
            "force_reanalysis": True
        }

        return success(data=analysis_data)

    except HTTPException:
        raise
    except Exception as e:
        import logging
        logger = logging.getLogger(__name__)
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –ø–µ—Ä–µ–∞–Ω–∞–ª–∏–∑–∞: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail={
                "error": "REANALYSIS_START_ERROR",
                "message": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –ø–µ—Ä–µ–∞–Ω–∞–ª–∏–∑–∞: {str(e)}"
            }
        )


@router.get("/results", response_model=APIResponse)
async def get_analysis_results(
    filters: AnalysisFilter = Depends(),
    current_user = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ AI –∞–Ω–∞–ª–∏–∑–∞
    –° —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ —Ä–∞–∑–ª–∏—á–Ω—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º
    """
    try:
        from app.models.application import Application, AnalysisResult

        # –ë–∞–∑–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å: —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–æ–ª—å–∫–æ –¥–ª—è –æ—Ç–∫–ª–∏–∫–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        query = db.query(AnalysisResult).join(Application).join(Application.vacancy).filter(
            Application.vacancy.has(user_id=current_user.id)
        )

        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –≤–∞–∫–∞–Ω—Å–∏–∏
        if filters.vacancy_id:
            query = query.filter(Application.vacancy_id == filters.vacancy_id)

        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–º—É score
        if filters.min_score is not None:
            query = query.filter(AnalysisResult.score >= filters.min_score)

        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–º—É score
        if filters.max_score is not None:
            query = query.filter(AnalysisResult.score <= filters.max_score)

        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if filters.recommendation:
            query = query.filter(AnalysisResult.recommendation == filters.recommendation)

        # –ü–æ–¥—Å—á–µ—Ç –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
        total = query.count()

        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏ –∏ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ score (–≤—ã—Å–æ–∫–∏–µ —Å–Ω–∞—á–∞–ª–∞)
        limit = filters.limit or 50
        offset = filters.offset or 0
        results = query.order_by(AnalysisResult.score.desc().nulls_last()).offset(offset).limit(limit).all()

        # –°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å –¥–∞–Ω–Ω—ã–º–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
        results_data = []
        for result in results:
            result_dict = result.to_dict()
            # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –∏–∑ —Å–≤—è–∑–∞–Ω–Ω–æ–≥–æ –æ—Ç–∫–ª–∏–∫–∞
            if result.application:
                result_dict['application'] = {
                    'candidate_name': result.application.candidate_name,
                    'candidate_email': result.application.candidate_email,
                    'candidate_phone': result.application.candidate_phone,
                    'resume_url': result.application.resume_url,
                    'created_at': result.application.created_at.isoformat() if result.application.created_at else None,
                }
            results_data.append(result_dict)

        return success(data={
            "results": results_data,
            "total": total,
            "limit": limit,
            "offset": offset,
            "filters_applied": filters.model_dump() if filters else None
        })
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail={
                "error": "RESULTS_FETCH_ERROR",
                "message": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞"
            }
        )


@router.get("/results/{analysis_id}", response_model=APIResponse)
async def get_analysis_result(
    analysis_id: str,
    current_user = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞
    –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ–¥–Ω–æ–º –∞–Ω–∞–ª–∏–∑–µ
    """
    # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    return success(data={
        "status": "TODO",
        "message": f"–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ {analysis_id} –±—É–¥–µ—Ç —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω",
        "analysis_id": analysis_id
    })


@router.delete("/results/{analysis_id}", response_model=APIResponse)
async def delete_analysis_result(
    analysis_id: str,
    current_user = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    –£–¥–∞–ª–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞
    –ü–æ–ª–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –∏–∑ —Å–∏—Å—Ç–µ–º—ã
    """
    # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —É–¥–∞–ª–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    return success(data={
        "status": "TODO",
        "message": f"–£–¥–∞–ª–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ {analysis_id} –±—É–¥–µ—Ç —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ",
        "analysis_id": analysis_id,
        "deleted": True
    })


@router.get("/vacancy/{vacancy_id}/stats", response_model=APIResponse)
async def get_vacancy_analysis_stats(
    vacancy_id: str,
    current_user = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –≤–∞–∫–∞–Ω—Å–∏–∏
    –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Ü–µ–Ω–æ–∫ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
    """
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –≤–∞–∫–∞–Ω—Å–∏–∏
        vacancy = db.query(Vacancy).filter(
            Vacancy.id == vacancy_id,
            Vacancy.user_id == current_user.id
        ).first()

        if not vacancy:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail={
                    "error": "VACANCY_NOT_FOUND",
                    "message": "–í–∞–∫–∞–Ω—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
                }
            )

        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è –≤–∞–∫–∞–Ω—Å–∏–∏
        results = db.query(AnalysisResult).join(
            Application, Application.id == AnalysisResult.application_id
        ).filter(
            Application.vacancy_id == vacancy_id
        ).all()

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        total = len(results)
        hire_count = len([r for r in results if r.recommendation == 'hire'])
        interview_count = len([r for r in results if r.recommendation == 'interview'])
        maybe_count = len([r for r in results if r.recommendation == 'maybe'])
        reject_count = len([r for r in results if r.recommendation == 'reject'])

        # –°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª
        avg_score = 0
        if total > 0:
            total_score = sum([r.score for r in results if r.score is not None])
            avg_score = round(total_score / total, 1) if total > 0 else 0

        # –ü–æ—Å–ª–µ–¥–Ω–∏–π –∞–Ω–∞–ª–∏–∑
        last_analysis_at = None
        if results:
            last_result = max(results, key=lambda r: r.created_at)
            last_analysis_at = last_result.created_at.isoformat()

        stats_data = {
            "vacancy_id": vacancy_id,
            "total_analyzed": total,
            "avg_score": avg_score,
            "hire_count": hire_count,
            "interview_count": interview_count,
            "maybe_count": maybe_count,
            "reject_count": reject_count,
            "last_analysis_at": last_analysis_at
        }

        return success(data=stats_data)

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting vacancy analysis stats: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail={
                "error": "STATS_FETCH_ERROR",
                "message": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"
            }
        )


@router.get("/export/excel")
async def export_analysis_to_excel(
    vacancy_id: str,
    recommendation: Optional[str] = None,
    min_score: Optional[int] = None,
    current_user = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    –≠–∫—Å–ø–æ—Ä—Ç –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ—Ç–∫–ª–∏–∫–æ–≤ –≤ Excel —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π

    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
    - vacancy_id: ID –≤–∞–∫–∞–Ω—Å–∏–∏ (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π)
    - recommendation: –§–∏–ª—å—Ç—Ä –ø–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (hire, interview, maybe, reject)
    - min_score: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–ª –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
    """
    try:
        from app.models.application import Application, AnalysisResult
        from app.models.vacancy import Vacancy
        import openpyxl
        from openpyxl.styles import Font, PatternFill, Alignment
        from datetime import datetime
        import tempfile
        import os

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–∏
        vacancy = db.query(Vacancy).filter(
            Vacancy.id == vacancy_id,
            Vacancy.user_id == current_user.id
        ).first()

        if not vacancy:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail={"error": "VACANCY_NOT_FOUND", "message": "–í–∞–∫–∞–Ω—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"}
            )

        # –ë–∞–∑–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π
        query = db.query(AnalysisResult, Application).join(
            Application,
            AnalysisResult.application_id == Application.id
        ).filter(
            Application.vacancy_id == vacancy_id
        )

        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤
        if recommendation:
            query = query.filter(AnalysisResult.recommendation == recommendation)

        if min_score is not None:
            query = query.filter(AnalysisResult.score >= min_score)

        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –æ—Ü–µ–Ω–∫–µ –æ—Ç –±–æ–ª—å—à–µ–π –∫ –º–µ–Ω—å—à–µ–π
        results = query.order_by(AnalysisResult.score.desc().nulls_last()).all()

        if not results:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail={"error": "NO_RESULTS", "message": "–ù–µ—Ç –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ—Ç–∫–ª–∏–∫–æ–≤"}
            )

        # –°–æ–∑–¥–∞–Ω–∏–µ Excel —Ñ–∞–π–ª–∞
        wb = openpyxl.Workbook()
        ws = wb.active
        ws.title = "AI –ê–Ω–∞–ª–∏–∑ –†–µ–∑—é–º–µ"

        # –î–æ–±–∞–≤–ª—è–µ–º –ª–∏—Å—Ç —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        stats_ws = wb.create_sheet("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", 0)

        # ========== –ë–†–ï–ù–î–ò–†–û–í–ê–ù–ù–´–ô –ó–ê–ì–û–õ–û–í–û–ö ==========
        # –õ–æ–≥–æ—Ç–∏–ø –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏ (—Å—Ç—Ä–æ–∫–∏ 1-3)
        ws.merge_cells('A1:O3')
        logo_cell = ws.cell(row=1, column=1, value="TIMLY\nAI-Powered HR Analytics")
        logo_cell.font = Font(bold=True, size=20, color="FFFFFF", name="Arial")
        logo_cell.alignment = Alignment(horizontal="center", vertical="center", wrap_text=True)
        logo_cell.fill = PatternFill(start_color="6366F1", end_color="8B5CF6", fill_type="solid")  # –ì—Ä–∞–¥–∏–µ–Ω—Ç —Å–∏–Ω–∏–π-—Ñ–∏–æ–ª–µ—Ç–æ–≤—ã–π
        ws.row_dimensions[1].height = 25
        ws.row_dimensions[2].height = 25
        ws.row_dimensions[3].height = 25

        # –ù–∞–∑–≤–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏ (—Å—Ç—Ä–æ–∫–∞ 4)
        ws.merge_cells('A4:O4')
        title_cell = ws.cell(row=4, column=1, value=f"üìã –í–∞–∫–∞–Ω—Å–∏—è: {vacancy.title}")
        title_cell.font = Font(bold=True, size=16, color="1F2937", name="Arial")
        title_cell.alignment = Alignment(horizontal="center", vertical="center")
        title_cell.fill = PatternFill(start_color="E0E7FF", end_color="E0E7FF", fill_type="solid")
        ws.row_dimensions[4].height = 30

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞—Ç–µ —ç–∫—Å–ø–æ—Ä—Ç–∞ (—Å—Ç—Ä–æ–∫–∞ 5)
        ws.merge_cells('A5:O5')
        date_cell = ws.cell(row=5, column=1, value=f"üìÖ –î–∞—Ç–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞: {datetime.now().strftime('%d.%m.%Y %H:%M')}")
        date_cell.font = Font(size=11, color="6B7280", italic=True)
        date_cell.alignment = Alignment(horizontal="center", vertical="center")
        ws.row_dimensions[5].height = 20

        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Ç–∞–±–ª–∏—Ü—ã (—Å—Ç—Ä–æ–∫–∞ 7 - –ø–æ—Å–ª–µ –±—Ä–µ–Ω–¥–∏–Ω–≥–∞)
        header = [
            "‚Ññ", "–ö–∞–Ω–¥–∏–¥–∞—Ç", "Email", "–¢–µ–ª–µ—Ñ–æ–Ω", "–°—Å—ã–ª–∫–∞ –Ω–∞ —Ä–µ–∑—é–º–µ",
            "–û—Ü–µ–Ω–∫–∞", "–ù–∞–≤—ã–∫–∏", "–û–ø—ã—Ç", "–ó–∞—Ä–ø–ª–∞—Ç–∞", "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è",
            "–°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã", "–°–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã", "–ö—Ä–∞—Å–Ω—ã–µ —Ñ–ª–∞–≥–∏",
            "–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ", "–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞"
        ]

        # –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å—Ç–∏–ª—å –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        header_fill = PatternFill(start_color="4F46E5", end_color="4F46E5", fill_type="solid")
        header_font = Font(bold=True, color="FFFFFF", size=12, name="Arial")

        for col, value in enumerate(header, 1):
            cell = ws.cell(row=7, column=col, value=value)
            cell.fill = header_fill
            cell.font = header_font
            cell.alignment = Alignment(horizontal="center", vertical="center", wrap_text=True)

        ws.row_dimensions[7].height = 30

        # –ó–∞–º–æ—Ä–æ–∑–∫–∞ –ø–∞–Ω–µ–ª–µ–π (–∑–∞–≥–æ–ª–æ–≤–æ–∫ –≤—Å–µ–≥–¥–∞ –≤–∏–¥–∏–º)
        ws.freeze_panes = "A8"

        # –°–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è —Ü–≤–µ—Ç–æ–≤–∞—è –ø–∞–ª–∏—Ç—Ä–∞ –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        rec_colors = {
            'hire': PatternFill(start_color="D1FAE5", end_color="D1FAE5", fill_type="solid"),  # –ú—è—Ç–Ω–æ-–∑–µ–ª–µ–Ω—ã–π
            'interview': PatternFill(start_color="FEF3C7", end_color="FEF3C7", fill_type="solid"),  # –¢–µ–ø–ª—ã–π –∂–µ–ª—Ç—ã–π
            'maybe': PatternFill(start_color="FBCFE8", end_color="FBCFE8", fill_type="solid"),  # –ú—è–≥–∫–∏–π —Ä–æ–∑–æ–≤—ã–π
            'reject': PatternFill(start_color="F3F4F6", end_color="F3F4F6", fill_type="solid")  # –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π —Å–µ—Ä—ã–π
        }

        rec_font_colors = {
            'hire': "065F46",  # –¢–µ–º–Ω–æ-–∑–µ–ª–µ–Ω—ã–π
            'interview': "92400E",  # –¢–µ–º–Ω–æ-–∂–µ–ª—Ç—ã–π
            'maybe': "9F1239",  # –¢–µ–º–Ω–æ-—Ä–æ–∑–æ–≤—ã–π
            'reject': "6B7280"  # –¢–µ–º–Ω–æ-—Å–µ—Ä—ã–π
        }

        # –ü–µ—Ä–µ–≤–æ–¥ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ —Ä—É—Å—Å–∫–∏–π —Å —ç–º–æ–¥–∑–∏
        rec_translations = {
            'hire': '‚úÖ –ù–∞–Ω—è—Ç—å',
            'interview': 'üë§ –°–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ',
            'maybe': 'ü§î –í–æ–∑–º–æ–∂–Ω–æ',
            'reject': '‚ùå –û—Ç–∫–ª–æ–Ω–∏—Ç—å'
        }

        # –î–∞–Ω–Ω—ã–µ (–Ω–∞—á–∏–Ω–∞–µ–º —Å 8-–π —Å—Ç—Ä–æ–∫–∏, —Ç.–∫. —Å—Ç—Ä–æ–∫–∏ 1-7 –∑–∞–Ω—è—Ç—ã –±—Ä–µ–Ω–¥–∏–Ω–≥–æ–º –∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏)
        for idx, (analysis, application) in enumerate(results, 8):
            ws.cell(row=idx, column=1, value=idx-7)  # –ù–æ–º–µ—Ä —Å—Ç—Ä–æ–∫–∏ (idx-7 —Ç.–∫. –Ω–∞—á–∏–Ω–∞–µ–º —Å 8)
            ws.cell(row=idx, column=2, value=application.candidate_name or "–ù–µ —É–∫–∞–∑–∞–Ω–æ")
            ws.cell(row=idx, column=3, value=application.candidate_email or "–ù–µ —É–∫–∞–∑–∞–Ω")
            ws.cell(row=idx, column=4, value=application.candidate_phone or "–ù–µ —É–∫–∞–∑–∞–Ω")

            # –°—Å—ã–ª–∫–∞ –Ω–∞ —Ä–µ–∑—é–º–µ
            if application.resume_url:
                cell = ws.cell(row=idx, column=5, value="–û—Ç–∫—Ä—ã—Ç—å —Ä–µ–∑—é–º–µ")
                cell.hyperlink = application.resume_url
                cell.font = Font(color="0563C1", underline="single")
            else:
                ws.cell(row=idx, column=5, value="–ù/–î")

            # –û—Ü–µ–Ω–∫–∏
            ws.cell(row=idx, column=6, value=analysis.score or 0)
            ws.cell(row=idx, column=7, value=analysis.skills_match or 0)
            ws.cell(row=idx, column=8, value=analysis.experience_match or 0)

            # –ó–∞—Ä–ø–ª–∞—Ç–∞
            salary_text = {
                'match': '–°–æ–≤–ø–∞–¥–∞–µ—Ç',
                'higher': '–í—ã—à–µ –æ–∂–∏–¥–∞–Ω–∏–π',
                'lower': '–ù–∏–∂–µ –æ–∂–∏–¥–∞–Ω–∏–π',
                'unknown': '–ù–µ —É–∫–∞–∑–∞–Ω–∞'
            }.get(analysis.salary_match, '–ù/–î')
            ws.cell(row=idx, column=9, value=salary_text)

            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è —Å —Ü–≤–µ—Ç–æ–º, —ç–º–æ–¥–∑–∏ –∏ –ø–µ—Ä–µ–≤–æ–¥–æ–º –Ω–∞ —Ä—É—Å—Å–∫–∏–π
            rec_text = rec_translations.get(analysis.recommendation, analysis.recommendation or "N/A")
            rec_cell = ws.cell(row=idx, column=10, value=rec_text)
            if analysis.recommendation and analysis.recommendation in rec_colors:
                rec_cell.fill = rec_colors[analysis.recommendation]
                rec_cell.font = Font(bold=True, size=11, color=rec_font_colors.get(analysis.recommendation, "000000"))
            rec_cell.alignment = Alignment(horizontal="center", vertical="center")

            ws.cell(row=idx, column=11, value=", ".join(analysis.strengths or []))
            ws.cell(row=idx, column=12, value=", ".join(analysis.weaknesses or []))
            ws.cell(row=idx, column=13, value=", ".join(analysis.red_flags or []))
            ws.cell(row=idx, column=14, value=analysis.reasoning or "")
            ws.cell(row=idx, column=15, value=analysis.created_at.strftime("%Y-%m-%d %H:%M") if analysis.created_at else "N/A")

        # ========== –ê–í–¢–û–§–ò–õ–¨–¢–† ==========
        # –í–∫–ª—é—á–∞–µ–º –∞–≤—Ç–æ—Ñ–∏–ª—å—Ç—Ä –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ (—Å—Ç—Ä–æ–∫–∞ 7)
        ws.auto_filter.ref = f"A7:O{len(results) + 7}"

        # ========== –£–°–õ–û–í–ù–û–ï –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–ï –î–õ–Ø –û–¶–ï–ù–û–ö ==========
        from openpyxl.styles import Color
        from openpyxl.formatting.rule import ColorScaleRule

        # –ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω–∞—è —Ä–∞—Å–∫—Ä–∞—Å–∫–∞ –¥–ª—è –∫–æ–ª–æ–Ω–∫–∏ "–û—Ü–µ–Ω–∫–∞" (F)
        score_rule = ColorScaleRule(
            start_type='num', start_value=0, start_color='FFC7CE',  # –ö—Ä–∞—Å–Ω—ã–π –¥–ª—è –Ω–∏–∑–∫–∏—Ö
            mid_type='num', mid_value=50, mid_color='FFEB9C',  # –ñ–µ–ª—Ç—ã–π –¥–ª—è —Å—Ä–µ–¥–Ω–∏—Ö
            end_type='num', end_value=100, end_color='C6EFCE'  # –ó–µ–ª–µ–Ω—ã–π –¥–ª—è –≤—ã—Å–æ–∫–∏—Ö
        )
        ws.conditional_formatting.add(f"F8:F{len(results) + 7}", score_rule)

        # –ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω–∞—è —Ä–∞—Å–∫—Ä–∞—Å–∫–∞ –¥–ª—è –∫–æ–ª–æ–Ω–∫–∏ "–ù–∞–≤—ã–∫–∏" (G)
        skills_rule = ColorScaleRule(
            start_type='num', start_value=0, start_color='FFC7CE',
            mid_type='num', mid_value=50, mid_color='FFEB9C',
            end_type='num', end_value=100, end_color='C6EFCE'
        )
        ws.conditional_formatting.add(f"G8:G{len(results) + 7}", skills_rule)

        # –ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω–∞—è —Ä–∞—Å–∫—Ä–∞—Å–∫–∞ –¥–ª—è –∫–æ–ª–æ–Ω–∫–∏ "–û–ø—ã—Ç" (H)
        exp_rule = ColorScaleRule(
            start_type='num', start_value=0, start_color='FFC7CE',
            mid_type='num', mid_value=50, mid_color='FFEB9C',
            end_type='num', end_value=100, end_color='C6EFCE'
        )
        ws.conditional_formatting.add(f"H8:H{len(results) + 7}", exp_rule)

        # ========== –ê–í–¢–û–®–ò–†–ò–ù–ê –ö–û–õ–û–ù–û–ö ==========
        from openpyxl.cell.cell import MergedCell
        for column in ws.columns:
            max_length = 0
            column_letter = None
            for cell in column:
                if isinstance(cell, MergedCell):
                    continue
                if column_letter is None:
                    column_letter = cell.column_letter
                try:
                    if len(str(cell.value)) > max_length:
                        max_length = len(str(cell.value))
                except:
                    pass
            if column_letter:
                adjusted_width = min(max_length + 2, 50)
                ws.column_dimensions[column_letter].width = adjusted_width

        # ========== –°–¢–†–ê–ù–ò–¶–ê –°–¢–ê–¢–ò–°–¢–ò–ö–ò ==========
        # –ë—Ä–µ–Ω–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
        stats_ws.merge_cells('A1:E3')
        stats_logo = stats_ws.cell(row=1, column=1, value="TIMLY\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–Ω–∞–ª–∏–∑–∞")
        stats_logo.font = Font(bold=True, size=18, color="FFFFFF", name="Arial")
        stats_logo.alignment = Alignment(horizontal="center", vertical="center", wrap_text=True)
        stats_logo.fill = PatternFill(start_color="8B5CF6", end_color="6366F1", fill_type="solid")
        stats_ws.row_dimensions[1].height = 20
        stats_ws.row_dimensions[2].height = 20
        stats_ws.row_dimensions[3].height = 20

        # –ù–∞–∑–≤–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏
        stats_ws.merge_cells('A4:E4')
        stats_title = stats_ws.cell(row=4, column=1, value=f"–í–∞–∫–∞–Ω—Å–∏—è: {vacancy.title}")
        stats_title.font = Font(bold=True, size=14, color="1F2937")
        stats_title.alignment = Alignment(horizontal="center", vertical="center")
        stats_title.fill = PatternFill(start_color="E0E7FF", end_color="E0E7FF", fill_type="solid")

        # –ü–æ–¥—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        total_count = len(results)
        hire_count = len([r for r, _ in results if r.recommendation == 'hire'])
        interview_count = len([r for r, _ in results if r.recommendation == 'interview'])
        maybe_count = len([r for r, _ in results if r.recommendation == 'maybe'])
        reject_count = len([r for r, _ in results if r.recommendation == 'reject'])
        avg_score = sum([r.score for r, _ in results if r.score]) / total_count if total_count > 0 else 0

        # –ö–∞—Ä—Ç–æ—á–∫–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ (–Ω–∞—á–∏–Ω–∞—è —Å–æ —Å—Ç—Ä–æ–∫–∏ 6)
        stats_data = [
            ("–í—Å–µ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤", total_count, "4F46E5"),
            ("–°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª", f"{avg_score:.1f}", "10B981"),
            ("–ù–∞–Ω—è—Ç—å ‚úÖ", hire_count, "059669"),
            ("–°–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ üë§", interview_count, "D97706"),
            ("–í–æ–∑–º–æ–∂–Ω–æ ü§î", maybe_count, "DB2777"),
            ("–û—Ç–∫–ª–æ–Ω–∏—Ç—å ‚ùå", reject_count, "6B7280"),
        ]

        row = 6
        for label, value, color in stats_data:
            stats_ws.merge_cells(f'A{row}:E{row}')
            cell = stats_ws.cell(row=row, column=1, value=f"{label}: {value}")
            cell.font = Font(bold=True, size=14, color="FFFFFF")
            cell.alignment = Alignment(horizontal="center", vertical="center")
            cell.fill = PatternFill(start_color=color, end_color=color, fill_type="solid")
            stats_ws.row_dimensions[row].height = 30
            row += 1

        # –ê–≤—Ç–æ—à–∏—Ä–∏–Ω–∞ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        for col in range(1, 6):
            stats_ws.column_dimensions[chr(64 + col)].width = 30

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".xlsx")
        wb.save(temp_file.name)
        temp_file.close()

        # –í–æ–∑–≤—Ä–∞—Ç —Ñ–∞–π–ª–∞
        from urllib.parse import quote

        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞ (—Ç–æ–ª—å–∫–æ ASCII)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        safe_filename = f"timly_analysis_{timestamp}.xlsx"

        # URL-encoded –∏–º—è –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–∞ —Å –∫–∏—Ä–∏–ª–ª–∏—Ü–µ–π
        display_filename = f"timly_analysis_{vacancy.title}_{timestamp}.xlsx"
        encoded_filename = quote(display_filename)

        return FileResponse(
            temp_file.name,
            media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            filename=safe_filename,
            headers={
                "Content-Disposition": f"attachment; filename={safe_filename}; filename*=UTF-8''{encoded_filename}"
            }
        )

    except Exception as e:
        import logging
        logger = logging.getLogger(__name__)
        logger.error(f"–û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ Excel: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail={"error": "EXPORT_ERROR", "message": f"–û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞: {str(e)}"}
        )


@router.get("/export/{export_job_id}/status", response_model=APIResponse)
async def get_export_status(
    export_job_id: str,
    current_user = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞
    –ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å —Ñ–∞–π–ª–∞ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
    """
    # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É —Å—Ç–∞—Ç—É—Å–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞
    export_status_data = {
        "export_job_id": export_job_id,
        "status": "completed",
        "file_size_bytes": 15360,
        "records_count": 25,
        "download_url": f"/api/analysis/export/{export_job_id}/download",
        "expires_at": "2024-01-03T00:00:00"
    }

    return success(data=export_status_data)


@router.get("/export/{export_job_id}/download")
async def download_export_file(
    export_job_id: str,
    current_user = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ Excel —Ñ–∞–π–ª–∞
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ñ–∞–π–ª –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
    """
    # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
    # file_path = f"/tmp/exports/{export_job_id}.xlsx"
    # return FileResponse(
    #     file_path,
    #     media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    #     filename=f"timly_analysis_{export_job_id}.xlsx"
    # )

    raise HTTPException(
        status_code=status.HTTP_501_NOT_IMPLEMENTED,
        detail={
            "error": "NOT_IMPLEMENTED",
            "message": "–°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –±—É–¥–µ—Ç —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ"
        }
    )


@router.get("/job/{job_id}/status", response_model=APIResponse)
async def get_analysis_job_status(
    job_id: str,
    current_user = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ —Ñ–æ–Ω–æ–≤–æ–π –∑–∞–¥–∞—á–∏ –∞–Ω–∞–ª–∏–∑–∞
    –ü—Ä–æ–≥—Ä–µ—Å—Å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    """
    # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–¥–∞—á–∏
    job_status_data = {
        "job_id": job_id,
        "status": "processing",
        "progress": 60,
        "total_applications": 5,
        "processed_applications": 3,
        "successful_analyses": 3,
        "failed_analyses": 0,
        "estimated_completion": "2024-01-01T10:02:00",
        "errors": []
    }

    return success(data=job_status_data)


@router.delete("/job/{job_id}", response_model=APIResponse)
async def cancel_analysis_job(
    job_id: str,
    current_user = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    –û—Ç–º–µ–Ω–∞ –≤—ã–ø–æ–ª–Ω—è—é—â–µ–π—Å—è –∑–∞–¥–∞—á–∏ –∞–Ω–∞–ª–∏–∑–∞
    –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Ñ–æ–Ω–æ–≤—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
    """
    # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –æ—Ç–º–µ–Ω—É –∑–∞–¥–∞—á–∏
    return success(data={
        "status": "TODO",
        "message": f"–û—Ç–º–µ–Ω–∞ –∑–∞–¥–∞—á–∏ –∞–Ω–∞–ª–∏–∑–∞ {job_id} –±—É–¥–µ—Ç —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞",
        "job_id": job_id,
        "cancelled": True
    })


@router.get("/dashboard", response_model=APIResponse)
async def get_analysis_dashboard(
    current_user = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    Dashboard —Å –æ–±—â–µ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –∞–Ω–∞–ª–∏–∑–æ–≤
    –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    """
    try:
        from app.models.application import Application, AnalysisResult
        from app.models.vacancy import Vacancy
        from sqlalchemy import func
        from datetime import datetime, timedelta

        # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–Ω–∞–ª–∏–∑–æ–≤
        total_analyses = db.query(func.count(AnalysisResult.id)).join(
            Application
        ).join(
            Vacancy
        ).filter(
            Vacancy.user_id == current_user.id
        ).scalar() or 0

        # –ê–Ω–∞–ª–∏–∑—ã –∑–∞ —ç—Ç–æ—Ç –º–µ—Å—è—Ü
        month_start = datetime.now().replace(day=1, hour=0, minute=0, second=0, microsecond=0)
        analyses_this_month = db.query(func.count(AnalysisResult.id)).join(
            Application
        ).join(
            Vacancy
        ).filter(
            Vacancy.user_id == current_user.id,
            AnalysisResult.created_at >= month_start
        ).scalar() or 0

        # –°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª
        avg_score = db.query(func.avg(AnalysisResult.score)).join(
            Application
        ).join(
            Vacancy
        ).filter(
            Vacancy.user_id == current_user.id,
            AnalysisResult.score.isnot(None)
        ).scalar() or 0

        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (score >= 80)
        top_candidates_count = db.query(func.count(AnalysisResult.id)).join(
            Application
        ).join(
            Vacancy
        ).filter(
            Vacancy.user_id == current_user.id,
            AnalysisResult.score >= 80
        ).scalar() or 0

        # –û–±—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –∞–Ω–∞–ª–∏–∑–æ–≤ (–≤ —Ä—É–±–ª—è—Ö, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –∫–æ–ø–µ–π–∫–∏ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
        total_cost_rub = db.query(func.sum(AnalysisResult.ai_cost_rub)).join(
            Application
        ).join(
            Vacancy
        ).filter(
            Vacancy.user_id == current_user.id,
            AnalysisResult.ai_cost_rub.isnot(None)
        ).scalar() or 0
        total_cost_cents = int(float(total_cost_rub) * 100) if total_cost_rub else 0

        # –°—Ç–æ–∏–º–æ—Å—Ç—å –∑–∞ —ç—Ç–æ—Ç –º–µ—Å—è—Ü
        cost_this_month_rub = db.query(func.sum(AnalysisResult.ai_cost_rub)).join(
            Application
        ).join(
            Vacancy
        ).filter(
            Vacancy.user_id == current_user.id,
            AnalysisResult.created_at >= month_start,
            AnalysisResult.ai_cost_rub.isnot(None)
        ).scalar() or 0
        cost_this_month_cents = int(float(cost_this_month_rub) * 100) if cost_this_month_rub else 0

        # –ù–µ–¥–∞–≤–Ω–∏–µ –∞–Ω–∞–ª–∏–∑—ã (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 10)
        recent_analyses_raw = db.query(
            AnalysisResult, Application, Vacancy
        ).join(
            Application,
            AnalysisResult.application_id == Application.id
        ).join(
            Vacancy,
            Application.vacancy_id == Vacancy.id
        ).filter(
            Vacancy.user_id == current_user.id
        ).order_by(
            AnalysisResult.created_at.desc()
        ).limit(10).all()

        recent_analyses = [
            {
                "vacancy_title": vacancy.title,
                "candidate_name": application.candidate_name or "–ë–µ–∑ –∏–º–µ–Ω–∏",
                "score": analysis.score or 0,
                "recommendation": analysis.recommendation or "unknown",
                "analyzed_at": analysis.created_at.isoformat() if analysis.created_at else None
            }
            for analysis, application, vacancy in recent_analyses_raw
        ]

        dashboard_data = {
            "total_analyses": total_analyses,
            "analyses_this_month": analyses_this_month,
            "avg_score": round(float(avg_score), 1) if avg_score else 0,
            "top_candidates_count": top_candidates_count,
            "total_cost_cents": total_cost_cents,
            "cost_this_month_cents": cost_this_month_cents,
            "recent_analyses": recent_analyses
        }

        return success(data=dashboard_data)

    except Exception as e:
        import logging
        logger = logging.getLogger(__name__)
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ dashboard: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail={"error": "DASHBOARD_ERROR", "message": f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {str(e)}"}
        )