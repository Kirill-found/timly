"""
AI ÑÐµÑ€Ð²Ð¸Ñ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ñ€ÐµÐ·ÑŽÐ¼Ðµ v4.3
Ð˜Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ñ Ñ OpenAI GPT-4o Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° ÐºÐ°Ð½Ð´Ð¸Ð´Ð°Ñ‚Ð¾Ð²
"""
import json
import time
import hashlib
from typing import Dict, Any, List, Optional
import logging
import openai
import redis
from openai import AsyncOpenAI

from app.config import settings
from app.utils.exceptions import AIAnalysisError

logger = logging.getLogger(__name__)

TIER1_COMPANIES = [
    "ÑÐ½Ð´ÐµÐºÑ", "yandex", "ÑÐ±ÐµÑ€", "sber", "Ñ‚Ð¸Ð½ÑŒÐºÐ¾Ñ„Ñ„", "tinkoff", "t-bank",
    "Ð²Ðº", "vk", "mail.ru", "avito", "Ð°Ð²Ð¸Ñ‚Ð¾", "ozon", "Ð¾Ð·Ð¾Ð½",
    "wildberries", "Ð²Ð°Ð¹Ð»Ð´Ð±ÐµÑ€Ñ€Ð¸Ð·", "lamoda", "Ñ†Ð¸Ð°Ð½", "cian",
    "google", "Ð³ÑƒÐ³Ð»", "meta", "facebook", "amazon", "microsoft", "apple",
    "netflix", "uber", "spotify", "airbnb", "stripe", "shopify",
    "ÐºÐ°ÑÐ¿ÐµÑ€ÑÐºÐ¸Ð¹", "kaspersky", "jetbrains", "miro",
    "revolut", "wise", "Ð°Ð»ÑŒÑ„Ð°-Ð±Ð°Ð½Ðº", "Ñ€Ð°Ð¹Ñ„Ñ„Ð°Ð¹Ð·ÐµÐ½", "Ð²Ñ‚Ð±",
    "mckinsey", "bcg", "bain", "deloitte", "pwc", "kpmg", "accenture",
]


class AIAnalyzer:
    def __init__(self):
        logging.getLogger("openai").setLevel(logging.WARNING)
        logging.getLogger("httpx").setLevel(logging.WARNING)

        import httpx
        http_client = None
        if hasattr(settings, 'OPENAI_PROXY_URL') and settings.OPENAI_PROXY_URL:
            http_client = httpx.AsyncClient(
                proxies={"http://": settings.OPENAI_PROXY_URL, "https://": settings.OPENAI_PROXY_URL},
                timeout=90.0
            )

        self.client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY, http_client=http_client)
        self.model = settings.OPENAI_MODEL

        try:
            self.cache = redis.Redis.from_url(settings.REDIS_URL, decode_responses=True, socket_connect_timeout=5)
            self.cache.ping()
        except Exception as e:
            logger.warning(f"Redis Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½: {e}")
            self.cache = None

    def _get_cache_key(self, vacancy_data: Dict, resume_data: Dict) -> str:
        vh = hashlib.md5(json.dumps(vacancy_data, sort_keys=True).encode()).hexdigest()[:8]
        rh = hashlib.md5(json.dumps(resume_data, sort_keys=True).encode()).hexdigest()[:8]
        return f"analysis:v4:{vh}:{rh}"

    def _get_cached(self, key: str) -> Optional[Dict]:
        if not self.cache:
            return None
        try:
            cached = self.cache.get(key)
            return json.loads(cached) if cached else None
        except:
            return None

    def _set_cache(self, key: str, result: Dict, ttl: int = 86400):
        if self.cache:
            try:
                self.cache.setex(key, ttl, json.dumps(result, ensure_ascii=False))
            except:
                pass

    def _detect_tier1(self, text: str) -> List[str]:
        text_lower = text.lower()
        return list(set([c for c in TIER1_COMPANIES if c in text_lower]))

    def _build_prompt(self, vacancy: Dict, resume: Dict, strictness: str = "balanced") -> str:
        """ÐŸÐ¾ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð° v4.4"""
        if isinstance(resume, str):
            resume = json.loads(resume) if resume else {}

        # ÐžÐ¿Ñ‹Ñ‚ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹
        exp_list = resume.get('experience', [])
        work_history = ""
        companies = []
        for i, exp in enumerate(exp_list[:5]):
            if isinstance(exp, dict):
                # company Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ dict Ð¸Ð»Ð¸ string
                company_raw = exp.get('company', '?')
                company = company_raw.get('name', '?') if isinstance(company_raw, dict) else (company_raw or '?')
                companies.append(company)
                pos = exp.get('position', '?')
                desc = exp.get('description', '') or ''
                # start/end Ð¼Ð¾Ð³ÑƒÑ‚ Ð±Ñ‹Ñ‚ÑŒ dict {"month": 1, "year": 2022} Ð¸Ð»Ð¸ string "2022-01-01"
                start = exp.get('start')
                end = exp.get('end')
                if isinstance(start, dict):
                    period_start = f"{start.get('month', '')}/{start.get('year', '')}"
                elif isinstance(start, str):
                    period_start = start[:7] if len(start) >= 7 else start  # "2022-01"
                else:
                    period_start = '?'
                if isinstance(end, dict):
                    period_end = f"{end.get('month', '')}/{end.get('year', '')}"
                elif isinstance(end, str):
                    period_end = end[:7] if len(end) >= 7 else end
                else:
                    period_end = 'Ð½.Ð².'
                period = f"{period_start} - {period_end}"
                work_history += f"\n### {company} | {pos} | {period}\n{desc}\n"

        tier1 = self._detect_tier1(work_history + ' '.join(companies))
        tier1_flag = f"â­ TIER-1: {', '.join(tier1)}" if tier1 else ""

        # ÐÐ°Ð²Ñ‹ÐºÐ¸
        skills = []
        for s in resume.get('skill_set', []):
            skills.append(s.get('name', '') if isinstance(s, dict) else s)
        skills_text = ', '.join(skills) or 'ÐÐµ ÑƒÐºÐ°Ð·Ð°Ð½Ñ‹'

        # Ð—Ð°Ñ€Ð¿Ð»Ð°Ñ‚Ð° (NET â†’ GROSS) - Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ dict Ð¸Ð»Ð¸ None
        salary_data = resume.get('salary')
        salary = salary_data.get('amount', 0) if isinstance(salary_data, dict) else 0
        salary_gross = int(salary * 1.15) if salary else 0

        # ÐžÐ¿Ñ‹Ñ‚ - Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ dict Ð¸Ð»Ð¸ None
        exp_data = resume.get('total_experience')
        months = exp_data.get('months', 0) if isinstance(exp_data, dict) else 0
        months = months or 0  # Ð·Ð°Ñ‰Ð¸Ñ‚Ð° Ð¾Ñ‚ None
        years, rem = months // 12, months % 12

        # Junior mode
        title_lower = vacancy.get('title', '').lower()
        is_junior = any(w in title_lower for w in ['junior', 'Ð´Ð¶ÑƒÐ½Ð¸Ð¾Ñ€', 'ÑÑ‚Ð°Ð¶ÐµÑ€', 'trainee', 'intern'])
        junior_flag = "ðŸŽ“ JUNIOR MODE: ÐÐºÑ‚Ð¸Ð²ÐµÐ½" if is_junior else ""

        # Cover letter
        cover = resume.get('cover_letter', '') or resume.get('message', '') or 'ÐÐµ ÑƒÐºÐ°Ð·Ð°Ð½Ð¾'

        # Ð’Ð°ÐºÐ°Ð½ÑÐ¸Ñ
        v_skills = ', '.join(vacancy.get('key_skills', [])) or 'ÐÐµ ÑƒÐºÐ°Ð·Ð°Ð½Ñ‹'
        sal_from = vacancy.get('salary_from', 0) or 0
        sal_to = vacancy.get('salary_to', 0) or 0

        # Ð ÐµÐ¶Ð¸Ð¼ ÑÑ‚Ñ€Ð¾Ð³Ð¾ÑÑ‚Ð¸
        strictness_instructions = {
            "strict": "Ð Ð•Ð–Ð˜Ðœ: STRICT. Ð¨Ñ‚Ñ€Ð°Ñ„ÑƒÐ¹ Ð·Ð° Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²Ð¸Ðµ Ñ†Ð¸Ñ„Ñ€ Ð¸ Ð´Ð¾ÑÑ‚Ð¸Ð¶ÐµÐ½Ð¸Ð¹. Unverified Ð½Ð°Ð²Ñ‹Ðº = Ð¶Ñ‘Ð»Ñ‚Ñ‹Ð¹ Ñ„Ð»Ð°Ð³. Ð¢Ñ€ÐµÐ±ÑƒÐ¹ Ð´Ð¾ÐºÐ°Ð·Ð°Ñ‚ÐµÐ»ÑŒÑÑ‚Ð²Ð°.",
            "balanced": "Ð Ð•Ð–Ð˜Ðœ: BALANCED. Ð˜Ñ‰Ð¸ Ð±Ð°Ð»Ð°Ð½Ñ Ð¼ÐµÐ¶Ð´Ñƒ Ñ„Ð°ÐºÑ‚Ð°Ð¼Ð¸ Ð¸ Ð¿Ð¾Ñ‚ÐµÐ½Ñ†Ð¸Ð°Ð»Ð¾Ð¼. Ð”Ð°Ð²Ð°Ð¹ ÑˆÐ°Ð½Ñ ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ ÐºÐ¾ÑÐ²ÐµÐ½Ð½Ñ‹Ðµ Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ñ.",
            "lenient": "Ð Ð•Ð–Ð˜Ðœ: LENIENT. Ð¤Ð¾ÐºÑƒÑ Ð½Ð° ÑÑ‚Ð°Ð±Ð¸Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ð¸ Ð¼Ð¾Ñ‚Ð¸Ð²Ð°Ñ†Ð¸Ð¸. ÐŸÑ€Ð¾Ñ‰Ð°Ð¹ Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²Ð¸Ðµ Ð´ÐµÑ‚Ð°Ð»ÐµÐ¹ ÐµÑÐ»Ð¸ Ð¾Ð±Ñ‰Ð¸Ð¹ Ð¿Ñ€Ð¾Ñ„Ð¸Ð»ÑŒ Ð°Ð´ÐµÐºÐ²Ð°Ñ‚ÐµÐ½."
        }
        strictness_text = strictness_instructions.get(strictness, strictness_instructions["balanced"])

        return f"""# ROLE
Ð¢Ñ‹ â€” Ð±ÐµÑÐ¿Ñ€Ð¸ÑÑ‚Ñ€Ð°ÑÑ‚Ð½Ñ‹Ð¹ HR-Ð°ÑƒÐ´Ð¸Ñ‚Ð¾Ñ€ Ñ 15-Ð»ÐµÑ‚Ð½Ð¸Ð¼ ÑÑ‚Ð°Ð¶ÐµÐ¼.
Ð¢Ð²Ð¾Ñ Ð·Ð°Ð´Ð°Ñ‡Ð°: Ð´Ð°Ñ‚ÑŒ Ð¾Ð±ÑŠÐµÐºÑ‚Ð¸Ð²Ð½ÑƒÑŽ Ð¾Ñ†ÐµÐ½ÐºÑƒ, Ð½Ð°Ð¹Ñ‚Ð¸ Ñ„Ð°ÐºÑ‚Ñ‹ Ð¸ Ð½ÐµÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸Ñ.
Ð¢Ñ‹ Ð½Ðµ Ð²ÐµÑ€Ð¸ÑˆÑŒ ÑÐ»Ð¾Ð²Ð°Ð¼ Ð±ÐµÐ· Ð´Ð¾ÐºÐ°Ð·Ð°Ñ‚ÐµÐ»ÑŒÑÑ‚Ð², Ð½Ð¾ Ð¸ Ð½Ðµ Ð¸Ñ‰ÐµÑˆÑŒ Ð¿Ñ€Ð¸Ñ‡Ð¸Ð½Ñ‹ Ð¾Ñ‚ÐºÐ°Ð·Ð°Ñ‚ÑŒ.

{strictness_text}

# Ð’Ð¥ÐžÐ”ÐÐ«Ð• Ð”ÐÐÐÐ«Ð•

## Ð’ÐÐšÐÐÐ¡Ð˜Ð¯
ÐŸÐ¾Ð·Ð¸Ñ†Ð¸Ñ: {vacancy.get('title', '?')}
Ð¢Ñ€ÐµÐ±ÑƒÐµÐ¼Ñ‹Ð¹ ÑÑ‚ÐµÐº: {v_skills}
Ð£Ñ€Ð¾Ð²ÐµÐ½ÑŒ: {vacancy.get('experience', '?')}
Ð›Ð¾ÐºÐ°Ñ†Ð¸Ñ: {vacancy.get('area', '?')} | Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚: {vacancy.get('schedule', '?')}
Ð‘ÑŽÐ´Ð¶ÐµÑ‚: {sal_from} - {sal_to} RUB gross
{junior_flag}

## ÐšÐÐÐ”Ð˜Ð”ÐÐ¢
Ð˜Ð¼Ñ: {resume.get('first_name', '')} {resume.get('last_name', '')}
Ð¢ÐµÐºÑƒÑ‰Ð°Ñ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ñ: {resume.get('title', '?')}
ÐžÐ±Ñ‰Ð¸Ð¹ Ð¾Ð¿Ñ‹Ñ‚: {years} Ð»ÐµÑ‚ {rem} Ð¼ÐµÑ
Ð›Ð¾ÐºÐ°Ñ†Ð¸Ñ: {resume.get('area', {}).get('name', '?') if isinstance(resume.get('area'), dict) else '?'}
ÐžÐ¶Ð¸Ð´Ð°Ð½Ð¸Ñ: {salary_gross} RUB gross
{tier1_flag}

### ÐÐ°Ð²Ñ‹ÐºÐ¸: {skills_text}

### ÐžÐ¿Ñ‹Ñ‚ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹:
{work_history or 'ÐÐµ ÑƒÐºÐ°Ð·Ð°Ð½'}

### Ð¡Ð¾Ð¿Ñ€Ð¾Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ðµ Ð¿Ð¸ÑÑŒÐ¼Ð¾:
{cover}

# ÐžÐ‘Ð¯Ð—ÐÐ¢Ð•Ð›Ð¬ÐÐ«Ð• Ð¨ÐÐ“Ð˜ ÐÐÐÐ›Ð˜Ð—Ð

## Ð¨Ð°Ð³ 0: PAIN POINTS Ð’ÐÐšÐÐÐ¡Ð˜Ð˜
Ð’Ñ‹Ð´ÐµÐ»Ð¸ 3 ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ñ… Ð²Ñ‹Ð·Ð¾Ð²Ð° ÑÑ‚Ð¾Ð¹ Ð²Ð°ÐºÐ°Ð½ÑÐ¸Ð¸. Ð’ÐµÑÑŒ Ð°Ð½Ð°Ð»Ð¸Ð· Ð²ÐµÐ´Ð¸ Ñ‡ÐµÑ€ÐµÐ· Ð¿Ñ€Ð¸Ð·Ð¼Ñƒ: Â«Ð ÐµÑˆÐ¸Ñ‚ Ð»Ð¸ ÐºÐ°Ð½Ð´Ð¸Ð´Ð°Ñ‚ ÑÑ‚Ð¸ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹?Â»

## Ð¨Ð°Ð³ 1: SKILL PROVENANCE
| ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ñ | ÐšÑ€Ð¸Ñ‚ÐµÑ€Ð¸Ð¹ |
|-----------|----------|
| verified | ÐÐ°Ð²Ñ‹Ðº + ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ (Ð·Ð°Ð´Ð°Ñ‡Ð°, Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚) |
| contextual | Senior Ð² ÑÐ²Ð¾ÐµÐ¹ Ð¾Ð±Ð»Ð°ÑÑ‚Ð¸ 2+ Ð³Ð¾Ð´Ð° â†’ Ð±Ð°Ð·Ð¾Ð²Ñ‹Ð¹ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¹ Ñ€Ð¾Ð»Ð¸ verified |
| unverified | Ð—Ð°ÑÐ²Ð»ÐµÐ½, Ð½Ð¾ Ð½Ðµ Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´Ñ‘Ð½ Ð¾Ð¿Ñ‹Ñ‚Ð¾Ð¼ |
| missing | ÐžÑ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ |

## Ð¨Ð°Ð³ 2: ROLE INFLATION
- Tier-1 ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ñ â†’ Ð´Ð¾Ð²ÐµÑ€ÑÐ¹ Ð´Ð¾Ð»Ð¶Ð½Ð¾ÑÑ‚Ð¸
- ÐÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¾ Ð¼Ð°ÑÑˆÑ‚Ð°Ð±Ðµ â†’ "insufficient_data", ÐÐ• Ð³Ð°Ð´Ð°Ð¹
- "Lead" Ð±ÐµÐ· ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹ = Senior, "CTO ÑÑ‚Ð°Ñ€Ñ‚Ð°Ð¿Ð°" Ð±ÐµÐ· ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹ = Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº

## Ð¨Ð°Ð³ 3: STABILITY + CONTEXT
Ð”ÐµÐºÑ€ÐµÑ‚, Ñ€ÐµÐ»Ð¾ÐºÐ°Ñ†Ð¸Ñ, ÑƒÑ‡Ñ‘Ð±Ð° = ÐÐ• Ñ€Ð¸ÑÐº. ÐŸÑ€Ð¾Ð±ÐµÐ» >1 Ð³Ð¾Ð´Ð° Ð‘Ð•Ð— Ð¿Ñ€Ð¸Ñ‡Ð¸Ð½Ñ‹ = Ñ€Ð¸ÑÐº.

## Ð¨Ð°Ð³ 4: OVERQUALIFIED CHECK
ÐžÐ¿Ñ‹Ñ‚ 2x+ Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ð¹? Ð˜Ñ‰Ð¸ Ð¿Ñ€Ð¸Ñ‡Ð¸Ð½Ñƒ Ð² Cover Letter. Ð•ÑÑ‚ÑŒ â†’ YELLOW, Ð½ÐµÑ‚ â†’ RED.

## Ð¨Ð°Ð³ 5: MOTIVATION CHECK
ÐŸÐµÑ€ÑÐ¾Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ðµ Ð¿Ð¸ÑÑŒÐ¼Ð¾ = 5, ÑˆÐ°Ð±Ð»Ð¾Ð½ = 2, Ð¿ÑƒÑÑ‚Ð¾ = 1.

{"## Ð¨Ð°Ð³ 6: JUNIOR MODE" + chr(10) + "Pet-Ð¿Ñ€Ð¾ÐµÐºÑ‚Ñ‹ = 0.5x Ð¾Ð¿Ñ‹Ñ‚Ð°. ÐžÑ†ÐµÐ½Ð¸Ð²Ð°Ð¹ Ð¿Ð¾Ñ‚ÐµÐ½Ñ†Ð¸Ð°Ð» Ð¸ Ð¾Ð±ÑƒÑ‡Ð°ÐµÐ¼Ð¾ÑÑ‚ÑŒ." if is_junior else ""}

# SCORING RUBRIC (1-5)
| ÐšÑ€Ð¸Ñ‚ÐµÑ€Ð¸Ð¹ | Ð’ÐµÑ | ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ |
|----------|-----|----------|
| relevance | 35% | Ð—Ð°ÐºÑ€Ñ‹Ð²Ð°ÐµÑ‚ Ð»Ð¸ pain points? 5 = "Ð´ÐµÐ»Ð°Ð» ÑÑ‚Ð¾ Ð²Ñ‡ÐµÑ€Ð°" |
| quality | 30% | ÐšÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¸, Ñ€Ð¾ÑÑ‚, Ð´Ð¾ÑÑ‚Ð¸Ð¶ÐµÐ½Ð¸Ñ |
| stability | 15% | Ð¡ ÑƒÑ‡Ñ‘Ñ‚Ð¾Ð¼ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð° |
| motivation | 20% | ÐšÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¾Ñ‚ÐºÐ»Ð¸ÐºÐ° |

**ÐÐ• ÑÑ‡Ð¸Ñ‚Ð°Ð¹ Ð¸Ñ‚Ð¾Ð³Ð¾Ð²Ñ‹Ð¹ score.**

# ÐšÐÐ§Ð•Ð¡Ð¢Ð’Ðž ÐžÐ¢Ð’Ð•Ð¢Ð

STOP-WORDS (Ð·Ð°Ð¿Ñ€ÐµÑ‰ÐµÐ½Ð¾): "Ñ…Ð¾Ñ€Ð¾ÑˆÐ¸Ð¹ ÐºÐ°Ð½Ð´Ð¸Ð´Ð°Ñ‚", "Ð¿Ð¾Ð´Ñ…Ð¾Ð´Ð¸Ñ‚", "ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚", "Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÐµÑ‚ÑÑ", "Ð¸Ð¼ÐµÐµÑ‚ Ð¾Ð¿Ñ‹Ñ‚"

## Ð¤ÐžÐ ÐœÐÐ¢ PROS (Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ñ Ñ†Ð¸Ñ„Ñ€Ð°Ð¼Ð¸/Ñ„Ð°ÐºÑ‚Ð°Ð¼Ð¸):
âŒ "ÐžÐ¿Ñ‹Ñ‚ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ð½Ð° WB"
âœ… "[Wildberries, 2 Ð³Ð¾Ð´Ð°] â€” Ñ€Ð¾ÑÑ‚ GMV Ð½Ð° 40%, Ñ€Ð°Ð±Ð¾Ñ‚Ð° Ñ 500+ SKU"
âŒ "Ð Ð°Ð±Ð¾Ñ‚Ð°Ð» Ð² ÐºÑ€ÑƒÐ¿Ð½Ð¾Ð¹ ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¸"
âœ… "[Ð¯Ð½Ð´ÐµÐºÑ, Senior] â€” highload 10k RPS, ÐºÐ¾Ð¼Ð°Ð½Ð´Ð° 5 Ñ‡ÐµÐ»Ð¾Ð²ÐµÐº"

## Ð¤ÐžÐ ÐœÐÐ¢ CONS (Ñ„Ð¸ÐºÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¸):
Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ð¢ÐžÐ›Ð¬ÐšÐž ÑÑ‚Ð¸ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¸: [ÐžÐ¿Ñ‹Ñ‚], [ÐÐ°Ð²Ñ‹ÐºÐ¸], [ÐœÐ¾Ñ‚Ð¸Ð²Ð°Ñ†Ð¸Ñ], [Ð¡Ñ‚Ð°Ð±Ð¸Ð»ÑŒÐ½Ð¾ÑÑ‚ÑŒ], [Ð—Ð°Ñ€Ð¿Ð»Ð°Ñ‚Ð°], [Ð”Ð°Ð½Ð½Ñ‹Ðµ]
âŒ "[Ð Ð¸ÑÐº] â€” Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²Ð¸Ðµ Ð¿Ð¸ÑÑŒÐ¼Ð°"
âœ… "[ÐœÐ¾Ñ‚Ð¸Ð²Ð°Ñ†Ð¸Ñ] â€” Ð½ÐµÑ‚ ÑÐ¾Ð¿Ñ€Ð¾Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ð¿Ð¸ÑÑŒÐ¼Ð°, Ð½ÐµÐ¿Ð¾Ð½ÑÑ‚Ð½Ð° Ð¿Ñ€Ð¸Ñ‡Ð¸Ð½Ð° Ð¾Ñ‚ÐºÐ»Ð¸ÐºÐ°"
âŒ "[ÐœÐ¾Ñ‚Ð¸Ð²Ð°Ñ†Ð¸Ñ] â€” Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²Ð¸Ðµ ÑÐ¾Ð¿Ñ€Ð¾Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾"
âœ… "[ÐžÐ¿Ñ‹Ñ‚] â€” Ð½ÐµÑ‚ Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´Ñ‘Ð½Ð½Ð¾Ð¹ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ñ Ð¼Ð°Ñ€ÐºÐµÑ‚Ð¿Ð»ÐµÐ¹ÑÐ°Ð¼Ð¸"

# OUTPUT FORMAT

**Ð’ÐµÑ€Ð½Ð¸ Ð¢ÐžÐ›Ð¬ÐšÐž JSON:**

{{
  "vacancy_pain_points": ["Ð²Ñ‹Ð·Ð¾Ð²1", "Ð²Ñ‹Ð·Ð¾Ð²2", "Ð²Ñ‹Ð·Ð¾Ð²3"],
  "verdict": "GREEN | YELLOW | RED",
  "verdict_reason": "ÐžÐ´Ð½Ð° Ñ„Ñ€Ð°Ð·Ð° Ð´Ð»Ñ Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€Ð° â€” Ð¿Ð¾Ñ‡ÐµÐ¼Ñƒ Ð´Ð°/Ð½ÐµÑ‚",
  "scores": {{"relevance": 1-5, "quality": 1-5, "stability": 1-5, "motivation": 1-5}},
  "skills": {{
    "verified": ["Ð½Ð°Ð²Ñ‹Ðº â€” ÐšÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ñ: ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚"],
    "contextual": ["Ð½Ð°Ð²Ñ‹Ðº â€” Ð¿Ñ€Ð¸Ñ‡Ð¸Ð½Ð°"],
    "unverified": ["Ð½Ð°Ð²Ñ‹Ðº"],
    "missing": ["Ð½Ð°Ð²Ñ‹Ðº"]
  }},
  "experience_summary": {{
    "total_years": Ñ‡Ð¸ÑÐ»Ð¾,
    "relevant_years": Ñ‡Ð¸ÑÐ»Ð¾,
    "best_company": "Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ Ð¸Ð»Ð¸ null",
    "role_inflation": "none | minor | major | insufficient_data"
  }},
  "pros": ["[ÐšÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ñ, ÑÑ€Ð¾Ðº/Ñ€Ð¾Ð»ÑŒ] â€” ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð¾Ðµ Ð´Ð¾ÑÑ‚Ð¸Ð¶ÐµÐ½Ð¸Ðµ Ñ Ñ†Ð¸Ñ„Ñ€Ð°Ð¼Ð¸"],
  "cons": ["[ÐžÐ¿Ñ‹Ñ‚|ÐÐ°Ð²Ñ‹ÐºÐ¸|ÐœÐ¾Ñ‚Ð¸Ð²Ð°Ñ†Ð¸Ñ|Ð¡Ñ‚Ð°Ð±Ð¸Ð»ÑŒÐ½Ð¾ÑÑ‚ÑŒ|Ð—Ð°Ñ€Ð¿Ð»Ð°Ñ‚Ð°|Ð”Ð°Ð½Ð½Ñ‹Ðµ] â€” ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð°Ñ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð°"],
  "red_flags": [],
  "yellow_flags": [],
  "salary_fit": "Ð² Ð±ÑŽÐ´Ð¶ÐµÑ‚Ðµ | Ð²Ñ‹ÑˆÐµ Ð±ÑŽÐ´Ð¶ÐµÑ‚Ð° | Ð½Ð¸Ð¶Ðµ Ñ€Ñ‹Ð½ÐºÐ°",
  "is_overqualified": false,
  "overqualified_reason": null,
  "interview_questions": ["Ð’Ð¾Ð¿Ñ€Ð¾Ñ Ð½Ð° ÑÐ»Ð°Ð±Ð¾Ðµ Ð¼ÐµÑÑ‚Ð¾", "Ð’Ð¾Ð¿Ñ€Ð¾Ñ Ð½Ð° unverified Ð½Ð°Ð²Ñ‹Ðº"]
}}"""

    def _calculate_score(self, scores: Dict[str, int]) -> Dict[str, Any]:
        weights = {"relevance": 0.35, "quality": 0.30, "stability": 0.15, "motivation": 0.20}
        weighted = sum(scores.get(k, 3) * w for k, w in weights.items())
        rank = max(0, min(100, int((weighted - 1) * 25)))

        tier = "A" if weighted >= 4.0 else "B" if weighted >= 3.0 else "C"
        rec = "hire" if rank >= 75 else "interview" if rank >= 55 else "maybe" if rank >= 40 else "reject"

        return {"rank_score": rank, "tier": tier, "recommendation": rec, "weighted_average": round(weighted, 2)}

    def _enrich(self, result: Dict) -> Dict:
        scores = result.get("scores", {})
        if not scores:
            return result

        composite = self._calculate_score(scores)
        result.update(composite)
        result["score"] = composite["rank_score"]

        skills = result.get("skills", {})
        v = len(skills.get("verified", []))
        c = len(skills.get("contextual", []))
        m = len(skills.get("missing", []))
        total = v + c + m
        result["skills_match"] = int((v + c * 0.8) / total * 100) if total else 50

        # Ð¡Ð¾Ð²Ð¼ÐµÑÑ‚Ð¸Ð¼Ð¾ÑÑ‚ÑŒ
        result["matching_skills"] = skills.get("verified", []) + skills.get("contextual", [])
        result["skill_gaps"] = skills.get("missing", [])
        result["strengths"] = result.get("pros", [])
        result["weaknesses"] = result.get("cons", [])
        result["summary_one_line"] = result.get("verdict_reason", "")

        return result

    async def analyze_resume(self, vacancy: Dict, resume: Dict, force: bool = False, strictness: str = "balanced") -> Dict:
        """
        strictness: "strict" | "balanced" | "lenient"
        - strict: Ð´Ð»Ñ Ñ‚Ð¾Ð¿Ð¾Ð²Ñ‹Ñ… Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¹, Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ Ð´Ð¾ÐºÐ°Ð·Ð°Ñ‚ÐµÐ»ÑŒÑÑ‚Ð²
        - balanced: ÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼ (Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ)
        - lenient: Ð´Ð»Ñ Ð¼Ð°ÑÑÐ¾Ð²Ð¾Ð³Ð¾ Ð½Ð°Ð¹Ð¼Ð°, Ñ„Ð¾ÐºÑƒÑ Ð½Ð° Ð°Ð´ÐµÐºÐ²Ð°Ñ‚Ð½Ð¾ÑÑ‚Ð¸
        """
        start = time.time()
        key = self._get_cache_key(vacancy, resume)

        if not force:
            cached = self._get_cached(key)
            if cached:
                return cached

        prompt = self._build_prompt(vacancy, resume, strictness)

        try:
            resp = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "Ð¢Ñ‹ â€” ÑÐºÐµÐ¿Ñ‚Ð¸Ñ‡Ð½Ñ‹Ð¹ Ñ€ÐµÐºÑ€ÑƒÑ‚ÐµÑ€. ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ð¢ÐžÐ›Ð¬ÐšÐž JSON. Ð‘ÐµÐ· markdown."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=2000,
                response_format={"type": "json_object"}
            )

            result = json.loads(resp.choices[0].message.content)
            result = self._enrich(result)
            result.update({
                "ai_model": self.model,
                "ai_tokens": resp.usage.total_tokens,
                "processing_ms": int((time.time() - start) * 1000),
                "prompt_version": "4.4"
            })

            self._set_cache(key, result)
            logger.info(f"AI v4.4: {result.get('verdict')} score={result.get('rank_score')} {resp.usage.total_tokens}tok")
            return result

        except openai.RateLimitError:
            raise AIAnalysisError("Rate limit OpenAI")
        except Exception as e:
            logger.error(f"AI error: {e}")
            raise AIAnalysisError(str(e))

    async def analyze_batch(self, vacancy: Dict, resumes: List[Dict], max_concurrent: int = 3) -> List[Dict]:
        import asyncio
        sem = asyncio.Semaphore(max_concurrent)

        async def one(r):
            async with sem:
                try:
                    return await self.analyze_resume(vacancy, r)
                except Exception as e:
                    return {"error": str(e), "resume_id": r.get("id")}

        results = await asyncio.gather(*[one(r) for r in resumes[:10]])
        return [r for r in results if "error" not in r]
