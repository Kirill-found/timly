"""
AI ÑÐµÑ€Ð²Ð¸Ñ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ñ€ÐµÐ·ÑŽÐ¼Ðµ v5.2
Ð˜Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ñ Ñ OpenAI GPT-4o Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° ÐºÐ°Ð½Ð´Ð¸Ð´Ð°Ñ‚Ð¾Ð²
Ð¤Ð¾ÐºÑƒÑ: Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð¾ÑÑ‚ÑŒ Ð¾Ð¿Ñ‹Ñ‚Ð°, Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ ÐºÐ°Ðº Ð±Ð¾Ð½ÑƒÑ
"""
import json
import time
import hashlib
from typing import Dict, Any, List, Optional
import logging
import openai
import redis
from openai import AsyncOpenAI

from app.config import settings
from app.utils.exceptions import AIAnalysisError

logger = logging.getLogger(__name__)


class AIAnalyzer:
    def __init__(self):
        logging.getLogger("openai").setLevel(logging.WARNING)
        logging.getLogger("httpx").setLevel(logging.WARNING)

        import httpx
        http_client = None
        if hasattr(settings, 'OPENAI_PROXY_URL') and settings.OPENAI_PROXY_URL:
            http_client = httpx.AsyncClient(
                proxies={"http://": settings.OPENAI_PROXY_URL, "https://": settings.OPENAI_PROXY_URL},
                timeout=90.0
            )

        self.client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY, http_client=http_client)
        self.model = settings.OPENAI_MODEL

        try:
            self.cache = redis.Redis.from_url(settings.REDIS_URL, decode_responses=True, socket_connect_timeout=5)
            self.cache.ping()
        except Exception as e:
            logger.warning(f"Redis Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½: {e}")
            self.cache = None

    def _get_cache_key(self, vacancy_data: Dict, resume_data: Dict) -> str:
        vh = hashlib.md5(json.dumps(vacancy_data, sort_keys=True).encode()).hexdigest()[:8]
        rh = hashlib.md5(json.dumps(resume_data, sort_keys=True).encode()).hexdigest()[:8]
        return f"analysis:v52:{vh}:{rh}"

    def _get_cached(self, key: str) -> Optional[Dict]:
        if not self.cache:
            return None
        try:
            cached = self.cache.get(key)
            return json.loads(cached) if cached else None
        except:
            return None

    def _set_cache(self, key: str, result: Dict, ttl: int = 86400):
        if self.cache:
            try:
                self.cache.setex(key, ttl, json.dumps(result, ensure_ascii=False))
            except:
                pass

    def _build_prompt(self, vacancy: Dict, resume: Dict, strictness: str = "balanced") -> str:
        """ÐŸÐ¾ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð° v5.1"""
        if isinstance(resume, str):
            resume = json.loads(resume) if resume else {}

        # ÐžÐ¿Ñ‹Ñ‚ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹
        exp_list = resume.get('experience', [])
        work_history = ""
        for i, exp in enumerate(exp_list[:5]):
            if isinstance(exp, dict):
                # company Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ dict Ð¸Ð»Ð¸ string
                company_raw = exp.get('company', '?')
                company = company_raw.get('name', '?') if isinstance(company_raw, dict) else (company_raw or '?')
                pos = exp.get('position', '?')
                desc = exp.get('description', '') or ''
                # start/end Ð¼Ð¾Ð³ÑƒÑ‚ Ð±Ñ‹Ñ‚ÑŒ dict {"month": 1, "year": 2022} Ð¸Ð»Ð¸ string "2022-01-01"
                start = exp.get('start')
                end = exp.get('end')
                if isinstance(start, dict):
                    period_start = f"{start.get('month', '')}/{start.get('year', '')}"
                elif isinstance(start, str):
                    period_start = start[:7] if len(start) >= 7 else start  # "2022-01"
                else:
                    period_start = '?'
                if isinstance(end, dict):
                    period_end = f"{end.get('month', '')}/{end.get('year', '')}"
                elif isinstance(end, str):
                    period_end = end[:7] if len(end) >= 7 else end
                else:
                    period_end = 'Ð½.Ð².'
                period = f"{period_start} - {period_end}"
                work_history += f"\n### {company} | {pos} | {period}\n{desc}\n"

        # ÐÐ°Ð²Ñ‹ÐºÐ¸
        skills = []
        for s in resume.get('skill_set', []):
            skills.append(s.get('name', '') if isinstance(s, dict) else s)
        skills_text = ', '.join(skills) or 'ÐÐµ ÑƒÐºÐ°Ð·Ð°Ð½Ñ‹'

        # Ð—Ð°Ñ€Ð¿Ð»Ð°Ñ‚Ð° (NET â†’ GROSS) - Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ dict Ð¸Ð»Ð¸ None
        salary_data = resume.get('salary')
        salary = salary_data.get('amount', 0) if isinstance(salary_data, dict) else 0
        salary_gross = int(salary * 1.15) if salary else 0

        # ÐžÐ¿Ñ‹Ñ‚ - Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ dict Ð¸Ð»Ð¸ None
        exp_data = resume.get('total_experience')
        months = exp_data.get('months', 0) if isinstance(exp_data, dict) else 0
        months = months or 0  # Ð·Ð°Ñ‰Ð¸Ñ‚Ð° Ð¾Ñ‚ None
        years, rem = months // 12, months % 12

        # Junior mode
        title_lower = vacancy.get('title', '').lower()
        is_junior = any(w in title_lower for w in ['junior', 'Ð´Ð¶ÑƒÐ½Ð¸Ð¾Ñ€', 'ÑÑ‚Ð°Ð¶ÐµÑ€', 'trainee', 'intern'])
        junior_flag = "ðŸŽ“ JUNIOR MODE: ÐÐºÑ‚Ð¸Ð²ÐµÐ½" if is_junior else ""

        # Cover letter
        cover = resume.get('cover_letter', '') or resume.get('message', '') or 'ÐÐµ ÑƒÐºÐ°Ð·Ð°Ð½Ð¾'

        # Ð’Ð°ÐºÐ°Ð½ÑÐ¸Ñ
        v_skills = ', '.join(vacancy.get('key_skills', [])) or 'ÐÐµ ÑƒÐºÐ°Ð·Ð°Ð½Ñ‹'
        sal_from = vacancy.get('salary_from', 0) or 0
        sal_to = vacancy.get('salary_to', 0) or 0

        # Ð ÐµÐ¶Ð¸Ð¼ ÑÑ‚Ñ€Ð¾Ð³Ð¾ÑÑ‚Ð¸
        strictness_instructions = {
            "strict": "Ð Ð•Ð–Ð˜Ðœ: STRICT. Ð¨Ñ‚Ñ€Ð°Ñ„ÑƒÐ¹ Ð·Ð° Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²Ð¸Ðµ Ñ†Ð¸Ñ„Ñ€ Ð¸ Ð´Ð¾ÑÑ‚Ð¸Ð¶ÐµÐ½Ð¸Ð¹. Unverified Ð½Ð°Ð²Ñ‹Ðº = Ð¶Ñ‘Ð»Ñ‚Ñ‹Ð¹ Ñ„Ð»Ð°Ð³. Ð¢Ñ€ÐµÐ±ÑƒÐ¹ Ð´Ð¾ÐºÐ°Ð·Ð°Ñ‚ÐµÐ»ÑŒÑÑ‚Ð²Ð°.",
            "balanced": "Ð Ð•Ð–Ð˜Ðœ: BALANCED. Ð˜Ñ‰Ð¸ Ð±Ð°Ð»Ð°Ð½Ñ Ð¼ÐµÐ¶Ð´Ñƒ Ñ„Ð°ÐºÑ‚Ð°Ð¼Ð¸ Ð¸ Ð¿Ð¾Ñ‚ÐµÐ½Ñ†Ð¸Ð°Ð»Ð¾Ð¼. Ð”Ð°Ð²Ð°Ð¹ ÑˆÐ°Ð½Ñ ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ ÐºÐ¾ÑÐ²ÐµÐ½Ð½Ñ‹Ðµ Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ñ.",
            "lenient": "Ð Ð•Ð–Ð˜Ðœ: LENIENT. Ð¤Ð¾ÐºÑƒÑ Ð½Ð° ÑÑ‚Ð°Ð±Ð¸Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ð¸ Ð¼Ð¾Ñ‚Ð¸Ð²Ð°Ñ†Ð¸Ð¸. ÐŸÑ€Ð¾Ñ‰Ð°Ð¹ Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²Ð¸Ðµ Ð´ÐµÑ‚Ð°Ð»ÐµÐ¹ ÐµÑÐ»Ð¸ Ð¾Ð±Ñ‰Ð¸Ð¹ Ð¿Ñ€Ð¾Ñ„Ð¸Ð»ÑŒ Ð°Ð´ÐµÐºÐ²Ð°Ñ‚ÐµÐ½."
        }
        strictness_text = strictness_instructions.get(strictness, strictness_instructions["balanced"])

        return f"""# Ð ÐžÐ›Ð¬
Ð¢Ñ‹ â€” Ð¿Ñ€Ð°ÐºÑ‚Ð¸Ñ‡Ð½Ñ‹Ð¹ HR-Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸Ðº. Ð¢Ð²Ð¾Ñ Ð·Ð°Ð´Ð°Ñ‡Ð° â€” Ð½Ð°Ð¹Ñ‚Ð¸ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ÑÑ‰Ð¸Ñ… ÐºÐ°Ð½Ð´Ð¸Ð´Ð°Ñ‚Ð¾Ð², Ð° Ð½Ðµ Ð¸Ð´ÐµÐ°Ð»ÑŒÐ½Ñ‹Ñ….

Ð¢Ð²Ð¾Ð¸ Ð¿Ñ€Ð¸Ð½Ñ†Ð¸Ð¿Ñ‹:
- Ð“Ð»Ð°Ð²Ð½Ð¾Ðµ â€” Ð Ð•Ð›Ð•Ð’ÐÐÐ¢ÐÐžÐ¡Ð¢Ð¬ Ð¾Ð¿Ñ‹Ñ‚Ð° Ð·Ð°Ð´Ð°Ñ‡Ð°Ð¼ Ð²Ð°ÐºÐ°Ð½ÑÐ¸Ð¸
- Ð¦Ð¸Ñ„Ñ€Ñ‹ Ð¸ Ð´Ð¾ÑÑ‚Ð¸Ð¶ÐµÐ½Ð¸Ñ â€” ÑÑ‚Ð¾ Ð‘ÐžÐÐ£Ð¡, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð²Ñ‹Ð´ÐµÐ»ÑÐµÑ‚ Ð»ÑƒÑ‡ÑˆÐ¸Ñ…
- ÐžÑ‚ÑÑƒÑ‚ÑÑ‚Ð²Ð¸Ðµ Ñ†Ð¸Ñ„Ñ€ â€” Ð½Ðµ Ð¿Ñ€Ð¸Ð³Ð¾Ð²Ð¾Ñ€, ÐµÑÐ»Ð¸ Ð¾Ð¿Ñ‹Ñ‚ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚ÐµÐ½
- ÐŸÑ€Ð¸Ð»Ð°Ð³Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ ("ÑƒÑÐ¿ÐµÑˆÐ½Ñ‹Ð¹", "ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹") Ð¸Ð³Ð½Ð¾Ñ€Ð¸Ñ€ÑƒÐ¹ â€” ÑÐ¼Ð¾Ñ‚Ñ€Ð¸ Ð½Ð° Ñ„Ð°ÐºÑ‚Ñ‹
- ÐžÑ†ÐµÐ½Ð¸Ð²Ð°Ð¹ Ð¿Ð¾Ñ‚ÐµÐ½Ñ†Ð¸Ð°Ð», Ð° Ð½Ðµ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¿Ñ€Ð¾ÑˆÐ»Ñ‹Ðµ Ð·Ð°ÑÐ»ÑƒÐ³Ð¸

{strictness_text}

# Ð—ÐÐ”ÐÐ§Ð
ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹ ÐºÐ°Ð½Ð´Ð¸Ð´Ð°Ñ‚Ð° Ð´Ð»Ñ Ð²Ð°ÐºÐ°Ð½ÑÐ¸Ð¸. ÐÐ°Ð¹Ð´Ð¸ Ñ‚ÐµÑ…, ÐºÑ‚Ð¾ ÐœÐžÐ–Ð•Ð¢ ÑÐ¿Ñ€Ð°Ð²Ð¸Ñ‚ÑŒÑÑ Ñ Ð·Ð°Ð´Ð°Ñ‡Ð°Ð¼Ð¸.

# Ð’ÐÐšÐÐÐ¡Ð˜Ð¯
ÐŸÐ¾Ð·Ð¸Ñ†Ð¸Ñ: {vacancy.get('title', '?')}
Ð¢Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ñ: {v_skills or vacancy.get('description', '')[:500]}
Ð£Ñ€Ð¾Ð²ÐµÐ½ÑŒ: {vacancy.get('experience', '?')}
Ð‘ÑŽÐ´Ð¶ÐµÑ‚: {sal_from} - {sal_to} RUB gross

# ÐšÐÐÐ”Ð˜Ð”ÐÐ¢
{resume.get('first_name', '')} {resume.get('last_name', '')} | {resume.get('title', '?')}
ÐžÐ¿Ñ‹Ñ‚: {years} Ð»ÐµÑ‚ {rem} Ð¼ÐµÑ | ÐžÐ¶Ð¸Ð´Ð°Ð½Ð¸Ñ: {salary_gross} RUB gross
{junior_flag}

## ÐžÐ¿Ñ‹Ñ‚ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹:
{work_history or 'ÐÐµ ÑƒÐºÐ°Ð·Ð°Ð½'}

## Ð¡Ð¾Ð¿Ñ€Ð¾Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ðµ:
{cover}

# ÐÐ›Ð“ÐžÐ Ð˜Ð¢Ðœ ÐÐÐÐ›Ð˜Ð—Ð

## 1. Ð§Ð¢Ðž ÐÐ£Ð–ÐÐž Ð ÐÐ‘ÐžÐ¢ÐžÐ”ÐÐ¢Ð•Ð›Ð®?
Ð’Ñ‹Ð´ÐµÐ»Ð¸ 3 Ð³Ð»Ð°Ð²Ð½Ñ‹Ñ… Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð¸Ð· Ð²Ð°ÐºÐ°Ð½ÑÐ¸Ð¸.

## 2. ÐžÐ¦Ð•ÐÐ˜ Ð Ð•Ð›Ð•Ð’ÐÐÐ¢ÐÐžÐ¡Ð¢Ð¬
Ð“Ð»Ð°Ð²Ð½Ñ‹Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ: ÑÐ¼Ð¾Ð¶ÐµÑ‚ Ð»Ð¸ ÐºÐ°Ð½Ð´Ð¸Ð´Ð°Ñ‚ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÑÑ‚ÑŒ ÑÑ‚Ð¸ Ð·Ð°Ð´Ð°Ñ‡Ð¸?
- Ð•ÑÑ‚ÑŒ Ð¿Ñ€ÑÐ¼Ð¾Ð¹ Ð¾Ð¿Ñ‹Ñ‚ Ð² Ð¿Ð¾Ñ…Ð¾Ð¶ÐµÐ¹ Ñ€Ð¾Ð»Ð¸?
- Ð Ð°Ð±Ð¾Ñ‚Ð°Ð» Ñ Ð½ÑƒÐ¶Ð½Ñ‹Ð¼Ð¸ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð°Ð¼Ð¸/Ð¿Ð»Ð¾Ñ‰Ð°Ð´ÐºÐ°Ð¼Ð¸?
- Ð”Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð¸ ÑÐ²ÐµÐ¶ÐµÑÑ‚ÑŒ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð¾Ð³Ð¾ Ð¾Ð¿Ñ‹Ñ‚Ð°?

## 3. Ð˜Ð—Ð’Ð›Ð•ÐšÐ˜ ÐœÐ•Ð¢Ð Ð˜ÐšÐ˜ (ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ)
âš ï¸ Ð’ÐÐ–ÐÐž: ÐŸÐ¸ÑˆÐ¸ Ñ†Ð¸Ñ„Ñ€Ñƒ Ð¢ÐžÐ›Ð¬ÐšÐž ÐµÑÐ»Ð¸ Ð¾Ð½Ð° Ð¯Ð’ÐÐž ÑƒÐºÐ°Ð·Ð°Ð½Ð° Ð² Ñ‚ÐµÐºÑÑ‚Ðµ.
Ð—ÐÐŸÐ Ð•Ð©Ð•ÐÐž ÑƒÐ³Ð°Ð´Ñ‹Ð²Ð°Ñ‚ÑŒ Ð¸Ð»Ð¸ ÑÐºÑÑ‚Ñ€Ð°Ð¿Ð¾Ð»Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ. ÐÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ… = null.
Ð˜Ñ‰Ð¸: Ð¾Ð±ÑŠÑ‘Ð¼ (Ñ‚Ð¾Ð²Ð°Ñ€Ñ‹, Ð·Ð°ÐºÐ°Ð·Ñ‹), Ð´ÐµÐ½ÑŒÐ³Ð¸ (Ð²Ñ‹Ñ€ÑƒÑ‡ÐºÐ°, Ð±ÑŽÐ´Ð¶ÐµÑ‚), Ñ€Ð¾ÑÑ‚ (%), ÐºÐ¾Ð¼Ð°Ð½Ð´Ð°.

## 4. Ð›ÐžÐ“Ð˜ÐšÐ Ð’Ð•Ð Ð”Ð˜ÐšÐ¢Ð
GREEN â€” Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ñ‹Ð¹ Ð¾Ð¿Ñ‹Ñ‚ + (Ñ†Ð¸Ñ„Ñ€Ñ‹ Ð˜Ð›Ð˜ ÑÑ‚Ð°Ð±Ð¸Ð»ÑŒÐ½Ð°Ñ ÐºÐ°Ñ€ÑŒÐµÑ€Ð°)
YELLOW â€” ÐµÑÑ‚ÑŒ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ñ‹Ð¹ Ð¾Ð¿Ñ‹Ñ‚, Ð½Ð¾ Ð½ÑƒÐ¶Ð½Ð¾ ÑƒÑ‚Ð¾Ñ‡Ð½Ð¸Ñ‚ÑŒ Ð´ÐµÑ‚Ð°Ð»Ð¸
RED â€” Ð½ÐµÑ‚ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð¾Ð³Ð¾ Ð¾Ð¿Ñ‹Ñ‚Ð° Ð˜Ð›Ð˜ ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð½ÐµÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸Ñ (Ð·Ð°Ñ€Ð¿Ð»Ð°Ñ‚Ð°, Ð»Ð¾ÐºÐ°Ñ†Ð¸Ñ)

âš ï¸ ÐžÑ‚ÑÑƒÑ‚ÑÑ‚Ð²Ð¸Ðµ Ñ†Ð¸Ñ„Ñ€ ÑÐ°Ð¼Ð¾ Ð¿Ð¾ ÑÐµÐ±Ðµ ÐÐ• Ð¿Ñ€Ð¸Ñ‡Ð¸Ð½Ð° Ð´Ð»Ñ RED. Ð­Ñ‚Ð¾ Ð¿Ñ€Ð¸Ñ‡Ð¸Ð½Ð° Ð´Ð»Ñ ÑƒÑ‚Ð¾Ñ‡Ð½ÑÑŽÑ‰Ð¸Ñ… Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ¾Ð².

## 5. Ð’Ð«Ð’ÐžÐ”
ÐšÑ€Ð°Ñ‚ÐºÐ¾: Ð¿Ð¾Ñ‡ÐµÐ¼Ñƒ ÑÑ‚Ð¾Ð¸Ñ‚/Ð½Ðµ ÑÑ‚Ð¾Ð¸Ñ‚ Ð·Ð²Ð°Ñ‚ÑŒ Ð½Ð° Ð¸Ð½Ñ‚ÐµÑ€Ð²ÑŒÑŽ.

# ÐŸÐ ÐÐ’Ð˜Ð›Ð Ð¤ÐžÐ ÐœÐ£Ð›Ð˜Ð ÐžÐ’ÐžÐš

Ð’ Ð¿Ð»ÑŽÑÐ°Ñ…/Ð¼Ð¸Ð½ÑƒÑÐ°Ñ… Ð¿Ð¸ÑˆÐ¸ ÐšÐžÐÐšÐ Ð•Ð¢ÐÐž:
âŒ "Ð£ÑÐ¿ÐµÑˆÐ½Ñ‹Ð¹ Ð¾Ð¿Ñ‹Ñ‚ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ð½Ð° Ð¼Ð°Ñ€ÐºÐµÑ‚Ð¿Ð»ÐµÐ¹ÑÐµ"
âœ… "WB 2 Ð³Ð¾Ð´Ð°: Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¸" Ð¸Ð»Ð¸ "WB: Ñ€Ð¾ÑÑ‚ Ð²Ñ‹Ñ€ÑƒÑ‡ÐºÐ¸ 500Kâ†’2M/Ð¼ÐµÑ"

âŒ "Ð Ð°Ð±Ð¾Ñ‚Ð°Ð» Ð² ÐºÑ€ÑƒÐ¿Ð½Ð¾Ð¹ ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¸"
âœ… "Ozon 2023-2024, Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€ Ð¿Ð¾ Ð·Ð°ÐºÑƒÐ¿ÐºÐ°Ð¼"

# Ð¤ÐžÐ ÐœÐÐ¢ ÐžÐ¢Ð’Ð•Ð¢Ð (Ñ‚Ð¾Ð»ÑŒÐºÐ¾ JSON)

{{
  "vacancy_needs": ["Ð·Ð°Ð´Ð°Ñ‡Ð° 1", "Ð·Ð°Ð´Ð°Ñ‡Ð° 2", "Ð·Ð°Ð´Ð°Ñ‡Ð° 3"],
  "candidate_metrics": [
    {{"name": "Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°", "value": "Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ Ð¸Ð»Ð¸ null", "period": "2023-2024 Ð¸Ð»Ð¸ null"}}
  ],
  "verdict": "GREEN | YELLOW | RED",
  "verdict_reason": "Ð—Ð²Ð¾Ð½Ð¸Ñ‚ÑŒ/Ð£Ñ‚Ð¾Ñ‡Ð½Ð¸Ñ‚ÑŒ/ÐžÑ‚ÐºÐ°Ð·: [Ð³Ð»Ð°Ð²Ð½Ñ‹Ð¹ Ñ„Ð°ÐºÑ‚]",
  "scores": {{"relevance": 1-5, "experience_quality": 1-5, "recency": 1-5}},
  "pros": ["ÐšÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ð¹ Ñ„Ð°ÐºÑ‚ Ð¸Ð· Ñ€ÐµÐ·ÑŽÐ¼Ðµ"],
  "cons": ["ÐšÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ð±ÐµÐ» Ð¸Ð»Ð¸ Ñ€Ð¸ÑÐº"],
  "missing_info": ["Ð§Ñ‚Ð¾ ÑƒÑ‚Ð¾Ñ‡Ð½Ð¸Ñ‚ÑŒ Ð½Ð° Ð¸Ð½Ñ‚ÐµÑ€Ð²ÑŒÑŽ"],
  "salary_fit": {{"status": "Ð² Ð±ÑŽÐ´Ð¶ÐµÑ‚Ðµ | Ð²Ñ‹ÑˆÐµ Ð±ÑŽÐ´Ð¶ÐµÑ‚Ð° | Ð½Ð¸Ð¶Ðµ Ð±ÑŽÐ´Ð¶ÐµÑ‚Ð°", "delta_percent": 0}},
  "interview_questions": ["Ð’Ð¾Ð¿Ñ€Ð¾Ñ Ð½Ð° Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÑƒ"]
}}"""

    def _calculate_score(self, scores: Dict[str, int]) -> Dict[str, Any]:
        # ÐÐ¾Ð²Ñ‹Ðµ Ð²ÐµÑÐ° Ð´Ð»Ñ v5.1: relevance, experience_quality, recency
        weights = {"relevance": 0.45, "experience_quality": 0.35, "recency": 0.20}
        weighted = sum(scores.get(k, 3) * w for k, w in weights.items())
        rank = max(0, min(100, int((weighted - 1) * 25)))

        tier = "A" if weighted >= 4.0 else "B" if weighted >= 3.0 else "C"
        rec = "hire" if rank >= 75 else "interview" if rank >= 55 else "maybe" if rank >= 40 else "reject"

        return {"rank_score": rank, "tier": tier, "recommendation": rec, "weighted_average": round(weighted, 2)}

    def _enrich(self, result: Dict) -> Dict:
        """ÐžÐ±Ð¾Ð³Ð°Ñ‰ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð° v5.1"""
        scores = result.get("scores", {})
        if not scores:
            return result

        composite = self._calculate_score(scores)
        result.update(composite)
        result["score"] = composite["rank_score"]

        # ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ ÐºÐ°Ð½Ð´Ð¸Ð´Ð°Ñ‚Ð° â€” ÑÑ‡Ð¸Ñ‚Ð°ÐµÐ¼ Ð·Ð°Ð¿Ð¾Ð»Ð½ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ
        metrics = result.get("candidate_metrics", [])
        filled = sum(1 for m in metrics if m.get("value") and m.get("value") != "null")
        result["metrics_filled"] = filled
        result["has_metrics"] = filled > 0

        # Ð¡Ð¾Ð²Ð¼ÐµÑÑ‚Ð¸Ð¼Ð¾ÑÑ‚ÑŒ ÑÐ¾ ÑÑ‚Ð°Ñ€Ñ‹Ð¼ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¾Ð¼ Ð´Ð»Ñ Excel
        result["strengths"] = result.get("pros", [])
        result["weaknesses"] = result.get("cons", [])
        result["summary_one_line"] = result.get("verdict_reason", "")

        # salary_fit â€” Ð¸Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ ÑÑ‚Ð°Ñ‚ÑƒÑ
        sal = result.get("salary_fit", {})
        if isinstance(sal, dict):
            result["salary_status"] = sal.get("status", "â€”")
            result["salary_delta"] = sal.get("delta_percent", 0)
        else:
            result["salary_status"] = sal
            result["salary_delta"] = 0

        return result

    async def analyze_resume(self, vacancy: Dict, resume: Dict, force: bool = False, strictness: str = "balanced") -> Dict:
        """
        strictness: "strict" | "balanced" | "lenient"
        - strict: Ð´Ð»Ñ Ñ‚Ð¾Ð¿Ð¾Ð²Ñ‹Ñ… Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¹, Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ Ð´Ð¾ÐºÐ°Ð·Ð°Ñ‚ÐµÐ»ÑŒÑÑ‚Ð²
        - balanced: ÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼ (Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ)
        - lenient: Ð´Ð»Ñ Ð¼Ð°ÑÑÐ¾Ð²Ð¾Ð³Ð¾ Ð½Ð°Ð¹Ð¼Ð°, Ñ„Ð¾ÐºÑƒÑ Ð½Ð° Ð°Ð´ÐµÐºÐ²Ð°Ñ‚Ð½Ð¾ÑÑ‚Ð¸
        """
        start = time.time()
        key = self._get_cache_key(vacancy, resume)

        if not force:
            cached = self._get_cached(key)
            if cached:
                return cached

        prompt = self._build_prompt(vacancy, resume, strictness)

        try:
            resp = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ð¢ÐžÐ›Ð¬ÐšÐž Ð²Ð°Ð»Ð¸Ð´Ð½Ñ‹Ð¼ JSON. Ð‘ÐµÐ· markdown, Ð±ÐµÐ· ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸ÐµÐ²."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=2000,
                response_format={"type": "json_object"}
            )

            result = json.loads(resp.choices[0].message.content)
            result = self._enrich(result)
            result.update({
                "ai_model": self.model,
                "ai_tokens": resp.usage.total_tokens,
                "processing_ms": int((time.time() - start) * 1000),
                "prompt_version": "5.2"
            })

            self._set_cache(key, result)
            logger.info(f"AI v5.1: {result.get('verdict')} score={result.get('rank_score')} metrics={result.get('metrics_filled', 0)}/3 {resp.usage.total_tokens}tok")
            return result

        except openai.RateLimitError:
            raise AIAnalysisError("Rate limit OpenAI")
        except Exception as e:
            logger.error(f"AI error: {e}")
            raise AIAnalysisError(str(e))

    async def analyze_batch(self, vacancy: Dict, resumes: List[Dict], max_concurrent: int = 3) -> List[Dict]:
        import asyncio
        sem = asyncio.Semaphore(max_concurrent)

        async def one(r):
            async with sem:
                try:
                    return await self.analyze_resume(vacancy, r)
                except Exception as e:
                    return {"error": str(e), "resume_id": r.get("id")}

        results = await asyncio.gather(*[one(r) for r in resumes[:10]])
        return [r for r in results if "error" not in r]
