"""
AI ÑÐµÑ€Ð²Ð¸Ñ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ñ€ÐµÐ·ÑŽÐ¼Ðµ v5.1
Ð˜Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ñ Ñ OpenAI GPT-4o Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° ÐºÐ°Ð½Ð´Ð¸Ð´Ð°Ñ‚Ð¾Ð²
Ð¤Ð¾ÐºÑƒÑ: ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ðµ Ð´Ð¾ÑÑ‚Ð¸Ð¶ÐµÐ½Ð¸Ñ, Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸, Ñ†Ð¸Ñ„Ñ€Ñ‹
"""
import json
import time
import hashlib
from typing import Dict, Any, List, Optional
import logging
import openai
import redis
from openai import AsyncOpenAI

from app.config import settings
from app.utils.exceptions import AIAnalysisError

logger = logging.getLogger(__name__)


class AIAnalyzer:
    def __init__(self):
        logging.getLogger("openai").setLevel(logging.WARNING)
        logging.getLogger("httpx").setLevel(logging.WARNING)

        import httpx
        http_client = None
        if hasattr(settings, 'OPENAI_PROXY_URL') and settings.OPENAI_PROXY_URL:
            http_client = httpx.AsyncClient(
                proxies={"http://": settings.OPENAI_PROXY_URL, "https://": settings.OPENAI_PROXY_URL},
                timeout=90.0
            )

        self.client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY, http_client=http_client)
        self.model = settings.OPENAI_MODEL

        try:
            self.cache = redis.Redis.from_url(settings.REDIS_URL, decode_responses=True, socket_connect_timeout=5)
            self.cache.ping()
        except Exception as e:
            logger.warning(f"Redis Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½: {e}")
            self.cache = None

    def _get_cache_key(self, vacancy_data: Dict, resume_data: Dict) -> str:
        vh = hashlib.md5(json.dumps(vacancy_data, sort_keys=True).encode()).hexdigest()[:8]
        rh = hashlib.md5(json.dumps(resume_data, sort_keys=True).encode()).hexdigest()[:8]
        return f"analysis:v5:{vh}:{rh}"

    def _get_cached(self, key: str) -> Optional[Dict]:
        if not self.cache:
            return None
        try:
            cached = self.cache.get(key)
            return json.loads(cached) if cached else None
        except:
            return None

    def _set_cache(self, key: str, result: Dict, ttl: int = 86400):
        if self.cache:
            try:
                self.cache.setex(key, ttl, json.dumps(result, ensure_ascii=False))
            except:
                pass

    def _build_prompt(self, vacancy: Dict, resume: Dict, strictness: str = "balanced") -> str:
        """ÐŸÐ¾ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð° v5.1"""
        if isinstance(resume, str):
            resume = json.loads(resume) if resume else {}

        # ÐžÐ¿Ñ‹Ñ‚ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹
        exp_list = resume.get('experience', [])
        work_history = ""
        for i, exp in enumerate(exp_list[:5]):
            if isinstance(exp, dict):
                # company Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ dict Ð¸Ð»Ð¸ string
                company_raw = exp.get('company', '?')
                company = company_raw.get('name', '?') if isinstance(company_raw, dict) else (company_raw or '?')
                pos = exp.get('position', '?')
                desc = exp.get('description', '') or ''
                # start/end Ð¼Ð¾Ð³ÑƒÑ‚ Ð±Ñ‹Ñ‚ÑŒ dict {"month": 1, "year": 2022} Ð¸Ð»Ð¸ string "2022-01-01"
                start = exp.get('start')
                end = exp.get('end')
                if isinstance(start, dict):
                    period_start = f"{start.get('month', '')}/{start.get('year', '')}"
                elif isinstance(start, str):
                    period_start = start[:7] if len(start) >= 7 else start  # "2022-01"
                else:
                    period_start = '?'
                if isinstance(end, dict):
                    period_end = f"{end.get('month', '')}/{end.get('year', '')}"
                elif isinstance(end, str):
                    period_end = end[:7] if len(end) >= 7 else end
                else:
                    period_end = 'Ð½.Ð².'
                period = f"{period_start} - {period_end}"
                work_history += f"\n### {company} | {pos} | {period}\n{desc}\n"

        # ÐÐ°Ð²Ñ‹ÐºÐ¸
        skills = []
        for s in resume.get('skill_set', []):
            skills.append(s.get('name', '') if isinstance(s, dict) else s)
        skills_text = ', '.join(skills) or 'ÐÐµ ÑƒÐºÐ°Ð·Ð°Ð½Ñ‹'

        # Ð—Ð°Ñ€Ð¿Ð»Ð°Ñ‚Ð° (NET â†’ GROSS) - Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ dict Ð¸Ð»Ð¸ None
        salary_data = resume.get('salary')
        salary = salary_data.get('amount', 0) if isinstance(salary_data, dict) else 0
        salary_gross = int(salary * 1.15) if salary else 0

        # ÐžÐ¿Ñ‹Ñ‚ - Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ dict Ð¸Ð»Ð¸ None
        exp_data = resume.get('total_experience')
        months = exp_data.get('months', 0) if isinstance(exp_data, dict) else 0
        months = months or 0  # Ð·Ð°Ñ‰Ð¸Ñ‚Ð° Ð¾Ñ‚ None
        years, rem = months // 12, months % 12

        # Junior mode
        title_lower = vacancy.get('title', '').lower()
        is_junior = any(w in title_lower for w in ['junior', 'Ð´Ð¶ÑƒÐ½Ð¸Ð¾Ñ€', 'ÑÑ‚Ð°Ð¶ÐµÑ€', 'trainee', 'intern'])
        junior_flag = "ðŸŽ“ JUNIOR MODE: ÐÐºÑ‚Ð¸Ð²ÐµÐ½" if is_junior else ""

        # Cover letter
        cover = resume.get('cover_letter', '') or resume.get('message', '') or 'ÐÐµ ÑƒÐºÐ°Ð·Ð°Ð½Ð¾'

        # Ð’Ð°ÐºÐ°Ð½ÑÐ¸Ñ
        v_skills = ', '.join(vacancy.get('key_skills', [])) or 'ÐÐµ ÑƒÐºÐ°Ð·Ð°Ð½Ñ‹'
        sal_from = vacancy.get('salary_from', 0) or 0
        sal_to = vacancy.get('salary_to', 0) or 0

        # Ð ÐµÐ¶Ð¸Ð¼ ÑÑ‚Ñ€Ð¾Ð³Ð¾ÑÑ‚Ð¸
        strictness_instructions = {
            "strict": "Ð Ð•Ð–Ð˜Ðœ: STRICT. Ð¨Ñ‚Ñ€Ð°Ñ„ÑƒÐ¹ Ð·Ð° Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²Ð¸Ðµ Ñ†Ð¸Ñ„Ñ€ Ð¸ Ð´Ð¾ÑÑ‚Ð¸Ð¶ÐµÐ½Ð¸Ð¹. Unverified Ð½Ð°Ð²Ñ‹Ðº = Ð¶Ñ‘Ð»Ñ‚Ñ‹Ð¹ Ñ„Ð»Ð°Ð³. Ð¢Ñ€ÐµÐ±ÑƒÐ¹ Ð´Ð¾ÐºÐ°Ð·Ð°Ñ‚ÐµÐ»ÑŒÑÑ‚Ð²Ð°.",
            "balanced": "Ð Ð•Ð–Ð˜Ðœ: BALANCED. Ð˜Ñ‰Ð¸ Ð±Ð°Ð»Ð°Ð½Ñ Ð¼ÐµÐ¶Ð´Ñƒ Ñ„Ð°ÐºÑ‚Ð°Ð¼Ð¸ Ð¸ Ð¿Ð¾Ñ‚ÐµÐ½Ñ†Ð¸Ð°Ð»Ð¾Ð¼. Ð”Ð°Ð²Ð°Ð¹ ÑˆÐ°Ð½Ñ ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ ÐºÐ¾ÑÐ²ÐµÐ½Ð½Ñ‹Ðµ Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ñ.",
            "lenient": "Ð Ð•Ð–Ð˜Ðœ: LENIENT. Ð¤Ð¾ÐºÑƒÑ Ð½Ð° ÑÑ‚Ð°Ð±Ð¸Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ð¸ Ð¼Ð¾Ñ‚Ð¸Ð²Ð°Ñ†Ð¸Ð¸. ÐŸÑ€Ð¾Ñ‰Ð°Ð¹ Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²Ð¸Ðµ Ð´ÐµÑ‚Ð°Ð»ÐµÐ¹ ÐµÑÐ»Ð¸ Ð¾Ð±Ñ‰Ð¸Ð¹ Ð¿Ñ€Ð¾Ñ„Ð¸Ð»ÑŒ Ð°Ð´ÐµÐºÐ²Ð°Ñ‚ÐµÐ½."
        }
        strictness_text = strictness_instructions.get(strictness, strictness_instructions["balanced"])

        return f"""# Ð ÐžÐ›Ð¬
Ð¢Ñ‹ â€” ÑÐºÐµÐ¿Ñ‚Ð¸Ñ‡Ð½Ñ‹Ð¹ Ð°ÑƒÐ´Ð¸Ñ‚Ð¾Ñ€ Ñ Ð°Ð»Ð»ÐµÑ€Ð³Ð¸ÐµÐ¹ Ð½Ð° bullshit.

Ð¢Ð²Ð¾Ð¸ Ð¿Ñ€Ð¸Ð½Ñ†Ð¸Ð¿Ñ‹:
- ÐÐµÑ‚ Ñ†Ð¸Ñ„Ñ€ = Ð½ÐµÑ‚ Ð´Ð¾ÑÑ‚Ð¸Ð¶ÐµÐ½Ð¸Ñ
- "Ð Ð°Ð±Ð¾Ñ‚Ð°Ð» Ð² ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¸ X" â€” ÑÑ‚Ð¾ Ð½Ðµ Ð·Ð°ÑÐ»ÑƒÐ³Ð°, ÑÑ‚Ð¾ Ñ„Ð°ÐºÑ‚ Ð±Ð¸Ð¾Ð³Ñ€Ð°Ñ„Ð¸Ð¸
- ÐŸÑ€Ð¸Ð»Ð°Ð³Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ ("ÑƒÑÐ¿ÐµÑˆÐ½Ñ‹Ð¹", "ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹") = Ð¿ÑƒÑÑ‚Ð¾Ð¹ Ð·Ð²ÑƒÐº
- Ð”Ð¾Ð²ÐµÑ€ÑÐ¹ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð³Ð»Ð°Ð³Ð¾Ð»Ð°Ð¼ Ñ Ñ†Ð¸Ñ„Ñ€Ð°Ð¼Ð¸: "ÑƒÐ²ÐµÐ»Ð¸Ñ‡Ð¸Ð» Ð½Ð° 40%", "Ð·Ð°Ð¿ÑƒÑÑ‚Ð¸Ð» 3 ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¸"
- Ð ÐµÐ·ÑŽÐ¼Ðµ Ð±ÐµÐ· ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð¸ÐºÐ¸ â€” ÑÑ‚Ð¾ Ð½Ðµ ÑÐºÑ€Ð¾Ð¼Ð½Ð¾ÑÑ‚ÑŒ, ÑÑ‚Ð¾ Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²

ÐŸÐ¾Ð¼Ð½Ð¸: Ð»ÑƒÑ‡ÑˆÐµ Ñ‡ÐµÑÑ‚Ð½Ñ‹Ð¹ RED Ñ Ð¾Ð±ÑŠÑÑÐ½ÐµÐ½Ð¸ÐµÐ¼, Ñ‡ÐµÐ¼ Ð²ÐµÐ¶Ð»Ð¸Ð²Ñ‹Ð¹ YELLOW Ð½Ð¸ Ð¾ Ñ‡Ñ‘Ð¼.

# Ð—ÐÐ”ÐÐ§Ð
ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹ ÐºÐ°Ð½Ð´Ð¸Ð´Ð°Ñ‚Ð° Ð´Ð»Ñ Ð²Ð°ÐºÐ°Ð½ÑÐ¸Ð¸. Ð¤Ð¾ÐºÑƒÑ Ð½Ð° ÐšÐžÐÐšÐ Ð•Ð¢ÐÐ«Ð¥ Ð”ÐžÐ¡Ð¢Ð˜Ð–Ð•ÐÐ˜Ð¯Ð¥ Ð¸ Ð¦Ð˜Ð¤Ð ÐÐ¥.

# Ð’ÐÐšÐÐÐ¡Ð˜Ð¯
ÐŸÐ¾Ð·Ð¸Ñ†Ð¸Ñ: {vacancy.get('title', '?')}
Ð¢Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ñ: {v_skills or vacancy.get('description', '')[:500]}
Ð£Ñ€Ð¾Ð²ÐµÐ½ÑŒ: {vacancy.get('experience', '?')}
Ð‘ÑŽÐ´Ð¶ÐµÑ‚: {sal_from} - {sal_to} RUB gross

# ÐšÐÐÐ”Ð˜Ð”ÐÐ¢
{resume.get('first_name', '')} {resume.get('last_name', '')} | {resume.get('title', '?')}
ÐžÐ¿Ñ‹Ñ‚: {years} Ð»ÐµÑ‚ {rem} Ð¼ÐµÑ | ÐžÐ¶Ð¸Ð´Ð°Ð½Ð¸Ñ: {salary_gross} RUB gross

## ÐžÐ¿Ñ‹Ñ‚ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹:
{work_history or 'ÐÐµ ÑƒÐºÐ°Ð·Ð°Ð½'}

## Ð¡Ð¾Ð¿Ñ€Ð¾Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ðµ:
{cover}

# ÐÐ›Ð“ÐžÐ Ð˜Ð¢Ðœ ÐÐÐÐ›Ð˜Ð—Ð

## 1. Ð§Ð¢Ðž ÐÐ£Ð–ÐÐž Ð ÐÐ‘ÐžÐ¢ÐžÐ”ÐÐ¢Ð•Ð›Ð®?
Ð’Ñ‹Ð´ÐµÐ»Ð¸ 3 Ð³Ð»Ð°Ð²Ð½Ñ‹Ñ… Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð¸Ð· Ð²Ð°ÐºÐ°Ð½ÑÐ¸Ð¸.

## 2. Ð˜Ð—Ð’Ð›Ð•ÐšÐ˜ ÐœÐ•Ð¢Ð Ð˜ÐšÐ˜ Ð˜Ð— Ð Ð•Ð—Ð®ÐœÐ•
âš ï¸ ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐ˜ Ð’ÐÐ–ÐÐž: ÐŸÐ¸ÑˆÐ¸ Ñ†Ð¸Ñ„Ñ€Ñƒ Ð¢ÐžÐ›Ð¬ÐšÐž ÐµÑÐ»Ð¸ Ð¾Ð½Ð° Ð¯Ð’ÐÐž ÑƒÐºÐ°Ð·Ð°Ð½Ð° Ð² Ñ‚ÐµÐºÑÑ‚Ðµ.
Ð—ÐÐŸÐ Ð•Ð©Ð•ÐÐž ÑƒÐ³Ð°Ð´Ñ‹Ð²Ð°Ñ‚ÑŒ, ÑÐºÑÑ‚Ñ€Ð°Ð¿Ð¾Ð»Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ, Ð¾ÐºÑ€ÑƒÐ³Ð»ÑÑ‚ÑŒ. ÐÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ… = null.

Ð˜Ñ‰Ð¸: Ð¾Ð±ÑŠÑ‘Ð¼ (Ñ‚Ð¾Ð²Ð°Ñ€Ñ‹, Ð·Ð°ÐºÐ°Ð·Ñ‹, ÐºÐ»Ð¸ÐµÐ½Ñ‚Ñ‹), Ð´ÐµÐ½ÑŒÐ³Ð¸ (Ð²Ñ‹Ñ€ÑƒÑ‡ÐºÐ°, Ð±ÑŽÐ´Ð¶ÐµÑ‚), Ñ€Ð¾ÑÑ‚ (%), ÐºÐ¾Ð¼Ð°Ð½Ð´Ð°, Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ñ‹.

## 3. Ð£Ð§Ð˜Ð¢Ð«Ð’ÐÐ™ ÐÐšÐ¢Ð£ÐÐ›Ð¬ÐÐžÐ¡Ð¢Ð¬
ÐŸÑ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚ â€” Ð´Ð¾ÑÑ‚Ð¸Ð¶ÐµÐ½Ð¸Ñ Ð·Ð° Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ 2 Ð³Ð¾Ð´Ð°.
Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ 3+ Ð»ÐµÑ‚Ð½ÐµÐ¹ Ð´Ð°Ð²Ð½Ð¾ÑÑ‚Ð¸ Ð¸Ð¼ÐµÑŽÑ‚ Ð¼ÐµÐ½ÑŒÑˆÐ¸Ð¹ Ð²ÐµÑ.

## 4. Ð¡ÐžÐŸÐžÐ¡Ð¢ÐÐ’Ð¬ Ð¡ ÐŸÐžÐ¢Ð Ð•Ð‘ÐÐžÐ¡Ð¢Ð¯ÐœÐ˜
- Ð•ÑÑ‚ÑŒ Ð¾Ð¿Ñ‹Ñ‚ Ñ Ñ†Ð¸Ñ„Ñ€Ð°Ð¼Ð¸ Ð·Ð° 2 Ð³Ð¾Ð´Ð° â†’ ÑÐ¸Ð»ÑŒÐ½Ð°Ñ ÑÑ‚Ð¾Ñ€Ð¾Ð½Ð°
- Ð•ÑÑ‚ÑŒ Ð¾Ð¿Ñ‹Ñ‚ Ð±ÐµÐ· Ñ†Ð¸Ñ„Ñ€ â†’ Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ ÑƒÑ‚Ð¾Ñ‡Ð½ÐµÐ½Ð¸Ñ
- ÐÐµÑ‚ Ð¾Ð¿Ñ‹Ñ‚Ð° â†’ ÑÐ»Ð°Ð±Ð°Ñ ÑÑ‚Ð¾Ñ€Ð¾Ð½Ð°

## 5. Ð’Ð«Ð’ÐžÐ”
"ÐŸÐ¾Ñ‡ÐµÐ¼Ñƒ Ð¡Ð¢ÐžÐ˜Ð¢/ÐÐ• Ð¡Ð¢ÐžÐ˜Ð¢ Ð·Ð²Ð°Ñ‚ÑŒ?" = Ñ„Ð°ÐºÑ‚, Ð½Ðµ Ð¼Ð½ÐµÐ½Ð¸Ðµ.

# ÐŸÐ ÐÐ’Ð˜Ð›Ð Ð¤ÐžÐ ÐœÐ£Ð›Ð˜Ð ÐžÐ’ÐžÐš

Ð—ÐÐŸÐ Ð•Ð©Ð•ÐÐž: "ÑƒÑÐ¿ÐµÑˆÐ½Ñ‹Ð¹", "ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹", "Ð¾Ð¿Ñ‹Ñ‚Ð½Ñ‹Ð¹", "ÐºÑ€ÑƒÐ¿Ð½Ñ‹Ð¹", "Ð¸Ð¼ÐµÐµÑ‚ Ð¾Ð¿Ñ‹Ñ‚", "Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð» Ð²", "Ð·Ð½Ð°ÐºÐ¾Ð¼ Ñ", "Ð¿Ð¾Ð´Ñ…Ð¾Ð´Ð¸Ñ‚"
Ð ÐÐ—Ð Ð•Ð¨Ð•ÐÐž: Ð³Ð»Ð°Ð³Ð¾Ð»Ñ‹ ("ÑƒÐ²ÐµÐ»Ð¸Ñ‡Ð¸Ð»", "Ð·Ð°Ð¿ÑƒÑÑ‚Ð¸Ð»", "Ð²Ð½ÐµÐ´Ñ€Ð¸Ð»") + Ñ†Ð¸Ñ„Ñ€Ñ‹ ("Ð²Ñ‹Ñ€ÑƒÑ‡ÐºÐ° 2M", "500 SKU", "ÐºÐ¾Ð¼Ð°Ð½Ð´Ð° 5 Ñ‡ÐµÐ»")

âŒ "Ð£ÑÐ¿ÐµÑˆÐ½Ñ‹Ð¹ Ð¾Ð¿Ñ‹Ñ‚ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ð½Ð° Ð¼Ð°Ñ€ÐºÐµÑ‚Ð¿Ð»ÐµÐ¹ÑÐµ"
âœ… "WB: ÑƒÐ²ÐµÐ»Ð¸Ñ‡Ð¸Ð» Ð²Ñ‹Ñ€ÑƒÑ‡ÐºÑƒ Ñ 500K Ð´Ð¾ 2M Ñ€ÑƒÐ±/Ð¼ÐµÑ Ð·Ð° 8 Ð¼ÐµÑ"

âŒ "Ð Ð°Ð±Ð¾Ñ‚Ð°Ð» Ð² ÐºÑ€ÑƒÐ¿Ð½Ð¾Ð¹ ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¸"
âœ… "Ozon, 2023-2024 â€” Ñ†Ð¸Ñ„Ñ€Ñ‹ Ð½Ðµ ÑƒÐºÐ°Ð·Ð°Ð½Ñ‹"

âŒ "ÐžÑ‚ÑÑƒÑ‚ÑÑ‚Ð²Ð¸Ðµ ÑÐ¾Ð¿Ñ€Ð¾Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ð¿Ð¸ÑÑŒÐ¼Ð°"
âœ… "ÐÐµ ÑƒÐºÐ°Ð·Ð°Ð½Ð° Ð¼Ð¾Ñ‚Ð¸Ð²Ð°Ñ†Ð¸Ñ Ð¿ÐµÑ€ÐµÑ…Ð¾Ð´Ð°"

# Ð¤ÐžÐ ÐœÐÐ¢ ÐžÐ¢Ð’Ð•Ð¢Ð (Ñ‚Ð¾Ð»ÑŒÐºÐ¾ JSON)

{{
  "vacancy_needs": ["Ð·Ð°Ð´Ð°Ñ‡Ð° 1", "Ð·Ð°Ð´Ð°Ñ‡Ð° 2", "Ð·Ð°Ð´Ð°Ñ‡Ð° 3"],
  "candidate_metrics": [
    {{"name": "Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°", "value": "Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ Ð¸Ð»Ð¸ null", "period": "2023-2024 Ð¸Ð»Ð¸ null"}},
    {{"name": "Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°", "value": "Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ Ð¸Ð»Ð¸ null", "period": "null"}},
    {{"name": "Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°", "value": "Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ Ð¸Ð»Ð¸ null", "period": "null"}}
  ],
  "verdict": "GREEN | YELLOW | RED",
  "verdict_reason": "Ð—Ð²Ð¾Ð½Ð¸Ñ‚ÑŒ/Ð£Ñ‚Ð¾Ñ‡Ð½Ð¸Ñ‚ÑŒ/ÐžÑ‚ÐºÐ°Ð·: [Ñ„Ð°ÐºÑ‚ Ð¸Ð· Ñ€ÐµÐ·ÑŽÐ¼Ðµ]",
  "scores": {{"relevance": 1-5, "experience_quality": 1-5, "recency": 1-5}},
  "pros": ["Ð“Ð»Ð°Ð³Ð¾Ð» + Ñ†Ð¸Ñ„Ñ€Ð° + ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚"],
  "cons": ["ÐŸÑ€Ð¾Ð±ÐµÐ» Ð¾Ñ‚Ð½Ð¾ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð²Ð°ÐºÐ°Ð½ÑÐ¸Ð¸"],
  "missing_info": ["Ð§Ñ‚Ð¾ ÑƒÑ‚Ð¾Ñ‡Ð½Ð¸Ñ‚ÑŒ Ð½Ð° Ð¸Ð½Ñ‚ÐµÑ€Ð²ÑŒÑŽ"],
  "salary_fit": {{"status": "Ð² Ð±ÑŽÐ´Ð¶ÐµÑ‚Ðµ | Ð²Ñ‹ÑˆÐµ Ð±ÑŽÐ´Ð¶ÐµÑ‚Ð° | Ð½Ð¸Ð¶Ðµ Ð±ÑŽÐ´Ð¶ÐµÑ‚Ð°", "delta_percent": 0}},
  "interview_questions": ["Ð’Ð¾Ð¿Ñ€Ð¾Ñ Ð½Ð° Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÑƒ"]
}}"""

    def _calculate_score(self, scores: Dict[str, int]) -> Dict[str, Any]:
        # ÐÐ¾Ð²Ñ‹Ðµ Ð²ÐµÑÐ° Ð´Ð»Ñ v5.1: relevance, experience_quality, recency
        weights = {"relevance": 0.45, "experience_quality": 0.35, "recency": 0.20}
        weighted = sum(scores.get(k, 3) * w for k, w in weights.items())
        rank = max(0, min(100, int((weighted - 1) * 25)))

        tier = "A" if weighted >= 4.0 else "B" if weighted >= 3.0 else "C"
        rec = "hire" if rank >= 75 else "interview" if rank >= 55 else "maybe" if rank >= 40 else "reject"

        return {"rank_score": rank, "tier": tier, "recommendation": rec, "weighted_average": round(weighted, 2)}

    def _enrich(self, result: Dict) -> Dict:
        """ÐžÐ±Ð¾Ð³Ð°Ñ‰ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð° v5.1"""
        scores = result.get("scores", {})
        if not scores:
            return result

        composite = self._calculate_score(scores)
        result.update(composite)
        result["score"] = composite["rank_score"]

        # ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ ÐºÐ°Ð½Ð´Ð¸Ð´Ð°Ñ‚Ð° â€” ÑÑ‡Ð¸Ñ‚Ð°ÐµÐ¼ Ð·Ð°Ð¿Ð¾Ð»Ð½ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ
        metrics = result.get("candidate_metrics", [])
        filled = sum(1 for m in metrics if m.get("value") and m.get("value") != "null")
        result["metrics_filled"] = filled
        result["has_metrics"] = filled > 0

        # Ð¡Ð¾Ð²Ð¼ÐµÑÑ‚Ð¸Ð¼Ð¾ÑÑ‚ÑŒ ÑÐ¾ ÑÑ‚Ð°Ñ€Ñ‹Ð¼ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¾Ð¼ Ð´Ð»Ñ Excel
        result["strengths"] = result.get("pros", [])
        result["weaknesses"] = result.get("cons", [])
        result["summary_one_line"] = result.get("verdict_reason", "")

        # salary_fit â€” Ð¸Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ ÑÑ‚Ð°Ñ‚ÑƒÑ
        sal = result.get("salary_fit", {})
        if isinstance(sal, dict):
            result["salary_status"] = sal.get("status", "â€”")
            result["salary_delta"] = sal.get("delta_percent", 0)
        else:
            result["salary_status"] = sal
            result["salary_delta"] = 0

        return result

    async def analyze_resume(self, vacancy: Dict, resume: Dict, force: bool = False, strictness: str = "balanced") -> Dict:
        """
        strictness: "strict" | "balanced" | "lenient"
        - strict: Ð´Ð»Ñ Ñ‚Ð¾Ð¿Ð¾Ð²Ñ‹Ñ… Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¹, Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ Ð´Ð¾ÐºÐ°Ð·Ð°Ñ‚ÐµÐ»ÑŒÑÑ‚Ð²
        - balanced: ÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼ (Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ)
        - lenient: Ð´Ð»Ñ Ð¼Ð°ÑÑÐ¾Ð²Ð¾Ð³Ð¾ Ð½Ð°Ð¹Ð¼Ð°, Ñ„Ð¾ÐºÑƒÑ Ð½Ð° Ð°Ð´ÐµÐºÐ²Ð°Ñ‚Ð½Ð¾ÑÑ‚Ð¸
        """
        start = time.time()
        key = self._get_cache_key(vacancy, resume)

        if not force:
            cached = self._get_cached(key)
            if cached:
                return cached

        prompt = self._build_prompt(vacancy, resume, strictness)

        try:
            resp = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ð¢ÐžÐ›Ð¬ÐšÐž Ð²Ð°Ð»Ð¸Ð´Ð½Ñ‹Ð¼ JSON. Ð‘ÐµÐ· markdown, Ð±ÐµÐ· ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸ÐµÐ²."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=2000,
                response_format={"type": "json_object"}
            )

            result = json.loads(resp.choices[0].message.content)
            result = self._enrich(result)
            result.update({
                "ai_model": self.model,
                "ai_tokens": resp.usage.total_tokens,
                "processing_ms": int((time.time() - start) * 1000),
                "prompt_version": "5.1"
            })

            self._set_cache(key, result)
            logger.info(f"AI v5.1: {result.get('verdict')} score={result.get('rank_score')} metrics={result.get('metrics_filled', 0)}/3 {resp.usage.total_tokens}tok")
            return result

        except openai.RateLimitError:
            raise AIAnalysisError("Rate limit OpenAI")
        except Exception as e:
            logger.error(f"AI error: {e}")
            raise AIAnalysisError(str(e))

    async def analyze_batch(self, vacancy: Dict, resumes: List[Dict], max_concurrent: int = 3) -> List[Dict]:
        import asyncio
        sem = asyncio.Semaphore(max_concurrent)

        async def one(r):
            async with sem:
                try:
                    return await self.analyze_resume(vacancy, r)
                except Exception as e:
                    return {"error": str(e), "resume_id": r.get("id")}

        results = await asyncio.gather(*[one(r) for r in resumes[:10]])
        return [r for r in results if "error" not in r]
